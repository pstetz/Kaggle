{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skew isn't working!\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "# <u>Table of Contents</u>\n",
    "1.) [TODO](#todo)  \n",
    "2.) [Imports](#imports)  \n",
    "3.) [Load data](#load)  \n",
    "4.) [Bureau Balance](#bureau_bal)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 4.1.) [Merge into Bureau](#merge_bureau_bal)  \n",
    "5.) [POS CASH balance](#pos_cash)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 5.1.) [Missing values](#pos_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 5.2.) [Merge into Previous Application](#merge_pos_cash)  \n",
    "6.) [Installment Payments](#install_pay)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 6.1.) [Missing values](#install_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 6.2.) [Merge into Previous Application](#merge_install_pay)  \n",
    "7.) [Credit Card Balance](#credit)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 7.1.) [Missing values](#credit_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 7.2.) [Merge into Previous Application](#merge_credit)  \n",
    "8.) [Final Data Prep](#final_merge)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 8.1.) [Missing values](#final_nan)  \n",
    "9.) [Modeling](#models)  \n",
    "10.) [Save file to CSV](#save)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"todo\"></a>\n",
    "\n",
    "# [^](#toc) <u>TODO</u>\n",
    "\n",
    "- Fix skew on columns (prev_app -> AMT_ANNUITY + AMT_APPLICATION)\n",
    "- Tinker with the best way to replace missing values (dropping cols?)\n",
    "- Look for outliers\n",
    "- Remove large outlier values from distributions\n",
    "- Include timeline relatoinships like MONTHS_BALANCE\n",
    "- Tune model parameters\n",
    "- Address [this](https://www.kaggle.com/c/home-credit-default-risk/discussion/57248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"imports\"></a>\n",
    "\n",
    "# [^](#toc) <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Time keeper\n",
    "import time\n",
    "\n",
    "# Statistics importrs\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Removes warnings from output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "def fillna_num(df):\n",
    "    missing_cols = [col for col in df.columns if any(df[col].isnull()) and df[col].dtype != object]\n",
    "    for col in missing_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def fillna_cat(df):\n",
    "    for col in [col for col in df if df[col].dtype==object]:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "def factorize_df(df, cats):\n",
    "    for col in cats:\n",
    "        df[col], _ = pd.factorize(df[col])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"load\"></a>\n",
    "\n",
    "# [^](#toc) <u>Load data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of bureau: (1716428, 17)\n",
      "Shape of prev_app: (1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/home_default/\"\n",
    "\n",
    "bureau   = pd.read_csv(DATA_PATH + \"bureau.csv\")\n",
    "prev_app = pd.read_csv(DATA_PATH + \"previous_application.csv\")\n",
    "\n",
    "print(\"Shape of bureau:\",    bureau.shape)\n",
    "print(\"Shape of prev_app:\",  prev_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values - Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:15<00:00,  2.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"DAYS_CREDIT_ENDDATE\", \"DAYS_ENDDATE_FACT\", \"AMT_CREDIT_MAX_OVERDUE\",\n",
    "        \"AMT_CREDIT_SUM\", \"AMT_CREDIT_SUM_DEBT\", \"AMT_CREDIT_SUM_LIMIT\",\n",
    "        \"AMT_ANNUITY\"]\n",
    "\n",
    "for col in tqdm(cols):\n",
    "    bureau[col + \"_nan\"] = bureau[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "#     mode                 = bureau[bureau[col].notnull()][col].mode().iloc[0]\n",
    "    bureau[col]          = bureau[col].fillna(0)\n",
    "    \n",
    "sum(bureau.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values - Previous application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fillin missing values with filler... NaN\n",
    "for col in (\"NAME_TYPE_SUITE\", \"PRODUCT_COMBINATION\"):\n",
    "    prev_app[col] = prev_app[col].fillna(\"NaN\")\n",
    "    \n",
    "### These values have to little counts, clump as one\n",
    "misc_vals = [\"Hobby\", \"Money for a third person\", \"Refusal to name the goal\"]\n",
    "misc_map = lambda x: \"Misc\" if x in misc_vals else x\n",
    "prev_app.NAME_CASH_LOAN_PURPOSE = prev_app.NAME_CASH_LOAN_PURPOSE.map(misc_map)\n",
    "\n",
    "### Drop outliers\n",
    "prev_app = prev_app.drop(\n",
    "                            prev_app[(prev_app.NAME_GOODS_CATEGORY == \"Animals\") |\n",
    "                                     (prev_app.NAME_GOODS_CATEGORY == \"House Construction\")].index)\n",
    "\n",
    "### Light missing values\n",
    "prev_app[\"AMT_CREDIT\"] = prev_app[\"AMT_CREDIT\"].fillna(prev_app[\"AMT_CREDIT\"].median())\n",
    "\n",
    "### Moderate missing values\n",
    "for col in (\"AMT_ANNUITY\", \"AMT_GOODS_PRICE\", \"CNT_PAYMENT\", \"AMT_DOWN_PAYMENT\", \"RATE_DOWN_PAYMENT\",\n",
    "            \"DAYS_FIRST_DRAWING\", \"DAYS_FIRST_DUE\", \"DAYS_LAST_DUE_1ST_VERSION\", \"DAYS_LAST_DUE\",\n",
    "            \"DAYS_TERMINATION\", \"NFLAG_INSURED_ON_APPROVAL\"):\n",
    "    prev_app[col + \"_nan\"] = prev_app[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "    prev_app[col] = prev_app[col].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "### Severe missing values\n",
    "for col in (\"RATE_INTEREST_PRIMARY\", \"RATE_INTEREST_PRIVILEGED\"):\n",
    "    prev_app[col] = prev_app[col].map(lambda x: 0 if np.isnan(x) else 1)\n",
    "    \n",
    "sum(prev_app.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bureau_bal\"></a>\n",
    "\n",
    "# [^](#toc) <u>Bureau Balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of bureau_balance: (27299925, 3)\n",
      "\n",
      "Columns of bureau_balance:\n",
      "SK_ID_BUREAU --- MONTHS_BALANCE --- STATUS\n"
     ]
    }
   ],
   "source": [
    "bureau_balance = pd.read_csv(DATA_PATH + \"bureau_balance.csv\")\n",
    "print(\"Shape of bureau_balance:\",  bureau_balance.shape)\n",
    "\n",
    "print(\"\\nColumns of bureau_balance:\")\n",
    "print(\" --- \".join(bureau_balance.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup bureau balance - get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = get_dummies(bureau_balance, [\"STATUS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_bureau_bal\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Bureau</u>\n",
    "\n",
    "FIXME: select features (1) max months, (2) most recent status (or few)), and (3) time weighted status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = merge_df.drop([\"MONTHS_BALANCE\", \"STATUS\"], axis=1)\n",
    "\n",
    "# prep for merge\n",
    "merge_df = merge_df.groupby(\"SK_ID_BUREAU\").sum().reset_index()\n",
    "\n",
    "### Add the median of the rest of the columns\n",
    "right    = bureau_balance.groupby(\"SK_ID_BUREAU\").median().reset_index()\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_BUREAU\").set_index(\"SK_ID_BUREAU\")\n",
    "\n",
    "### Remember added columns\n",
    "merged_cols = ['bur_bal_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "# Merge\n",
    "bureau = bureau.merge(right=merge_df.reset_index(), how='left', on='SK_ID_BUREAU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau[\"no_bureau_bal\"] = bureau[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "bureau[merged_cols]     = bureau[merged_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"pos_cash\"></a>\n",
    "\n",
    "# [^](#toc) <u>POS CASH balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pcb: (10001358, 8)\n",
      "\n",
      "Columns of pcb:\n",
      "SK_ID_PREV --- SK_ID_CURR --- MONTHS_BALANCE --- CNT_INSTALMENT --- CNT_INSTALMENT_FUTURE --- NAME_CONTRACT_STATUS --- SK_DPD --- SK_DPD_DEF\n"
     ]
    }
   ],
   "source": [
    "pcb = pd.read_csv(DATA_PATH + \"POS_CASH_balance.csv\")\n",
    "print(\"Shape of pcb:\",  pcb.shape)\n",
    "\n",
    "print(\"\\nColumns of pcb:\")\n",
    "print(\" --- \".join(pcb.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pos_nan\"></a>\n",
    "\n",
    "### [^](#toc) Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"CNT_INSTALMENT\", \"CNT_INSTALMENT_FUTURE\"):\n",
    "    pcb[col] = pcb[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcb = pcb.drop(pcb[pcb.NAME_CONTRACT_STATUS.isin([\"XNA\", \"Canceled\"])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = pcb[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "merge_df = get_dummies(merge_df, [\"NAME_CONTRACT_STATUS\"])\n",
    "merge_df = merge_df.drop(\"NAME_CONTRACT_STATUS\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_pos_cash\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep for merge\n",
    "count    = merge_df.groupby(\"SK_ID_PREV\").count()\n",
    "merge_df = merge_df.groupby(\"SK_ID_PREV\").sum().reset_index()\n",
    "merge_df[\"N\"] = list(count.iloc[:,0])\n",
    "\n",
    "right    = pcb.drop(\"SK_ID_CURR\", axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")\n",
    "\n",
    "merged_cols = ['pos_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "# Merge\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:10<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "prev_app[\"no_pcb\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null      = prev_app[col].notnull()\n",
    "    mode          = prev_app[not_null][col].mode()\n",
    "    prev_app[col] = prev_app[col].fillna(mode)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"install_pay\"></a>\n",
    "\n",
    "# [^](#toc) <u>Installment Payments</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of install_pay: (13605401, 8)\n",
      "\n",
      "Columns of install_pay:\n",
      "SK_ID_PREV --- SK_ID_CURR --- NUM_INSTALMENT_VERSION --- NUM_INSTALMENT_NUMBER --- DAYS_INSTALMENT --- DAYS_ENTRY_PAYMENT --- AMT_INSTALMENT --- AMT_PAYMENT\n"
     ]
    }
   ],
   "source": [
    "install_pay = pd.read_csv(DATA_PATH + \"installments_payments.csv\")\n",
    "print(\"Shape of install_pay:\",  install_pay.shape)\n",
    "\n",
    "print(\"\\nColumns of install_pay:\")\n",
    "print(\" --- \".join(install_pay.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing values</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"DAYS_ENTRY_PAYMENT\", \"AMT_PAYMENT\"):\n",
    "    install_pay[col + \"_nan\"] = install_pay[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "    install_pay[col] = install_pay[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install_pay[\"AMT_MISSING\"] = install_pay[\"AMT_INSTALMENT\"] - install_pay[\"AMT_PAYMENT\"]\n",
    "temp = install_pay.groupby(\"SK_ID_PREV\")[\"AMT_MISSING\"]\n",
    "\n",
    "merge_df = pd.DataFrame({\n",
    "    \"INSTALL_missing_max\": temp.max(),\n",
    "    \"INSTALL_missing_min\": temp.min(),\n",
    "    \"INSTALL_missing_med\": temp.median(),\n",
    "    \"INSTALL_payment_nan\": install_pay.groupby(\"SK_ID_PREV\")[\"AMT_PAYMENT_nan\"].sum(),\n",
    "    \"INSTALL_N\":           temp.count()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = install_pay.drop(\"SK_ID_CURR\", axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.reset_index()\n",
    "\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")\n",
    "merged_cols = merge_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_install_pay\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:15<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "prev_app[\"no_install\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null      = prev_app[col].notnull()\n",
    "    mode          = prev_app[not_null][col].mode()\n",
    "    prev_app[col] = prev_app[col].fillna(mode)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"credit\"></a>\n",
    "\n",
    "# [^](#toc) <u>Credit Card Balance</u>\n",
    "\n",
    "FIXME: select (1) max months of credit history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of credit_card: (3840312, 23)\n",
      "\n",
      "Columns of credit_card:\n",
      "SK_ID_PREV --- SK_ID_CURR --- MONTHS_BALANCE --- AMT_BALANCE --- AMT_CREDIT_LIMIT_ACTUAL --- AMT_DRAWINGS_ATM_CURRENT --- AMT_DRAWINGS_CURRENT --- AMT_DRAWINGS_OTHER_CURRENT --- AMT_DRAWINGS_POS_CURRENT --- AMT_INST_MIN_REGULARITY --- AMT_PAYMENT_CURRENT --- AMT_PAYMENT_TOTAL_CURRENT --- AMT_RECEIVABLE_PRINCIPAL --- AMT_RECIVABLE --- AMT_TOTAL_RECEIVABLE --- CNT_DRAWINGS_ATM_CURRENT --- CNT_DRAWINGS_CURRENT --- CNT_DRAWINGS_OTHER_CURRENT --- CNT_DRAWINGS_POS_CURRENT --- CNT_INSTALMENT_MATURE_CUM --- NAME_CONTRACT_STATUS --- SK_DPD --- SK_DPD_DEF\n"
     ]
    }
   ],
   "source": [
    "credit_card = pd.read_csv(DATA_PATH + \"credit_card_balance.csv\")\n",
    "print(\"Shape of credit_card:\",  credit_card.shape)\n",
    "\n",
    "print(\"\\nColumns of credit_card:\")\n",
    "print(\" --- \".join(credit_card.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"credit_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing Values and Outliers</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "### Remove outliers\n",
    "# Gets indices with outlier values\n",
    "temp = credit_card[credit_card.NAME_CONTRACT_STATUS.isin([\"Refused\", \"Approved\"])].index\n",
    "\n",
    "# Drops outlier values\n",
    "credit_card = credit_card.drop(temp, axis=0)\n",
    "\n",
    "# ------------------------------\n",
    "#### Fill in missing values\n",
    "cols = [\n",
    "        \"AMT_DRAWINGS_ATM_CURRENT\", \"AMT_DRAWINGS_OTHER_CURRENT\", \"AMT_DRAWINGS_POS_CURRENT\", \n",
    "        \"AMT_INST_MIN_REGULARITY\", \"AMT_PAYMENT_CURRENT\", \"CNT_DRAWINGS_ATM_CURRENT\", \n",
    "        \"CNT_DRAWINGS_OTHER_CURRENT\", \"CNT_DRAWINGS_POS_CURRENT\", \"CNT_INSTALMENT_MATURE_CUM\"\n",
    "]\n",
    "for col in tqdm(cols):\n",
    "    not_null = credit_card[col].notnull()\n",
    "    mode = float(credit_card[not_null][col].mode())\n",
    "    credit_card[col] = credit_card[col].fillna(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = credit_card[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "temp = get_dummies(temp, [\"NAME_CONTRACT_STATUS\"])\n",
    "temp = temp.drop(\"NAME_CONTRACT_STATUS\", axis=1)\n",
    "temp = temp.groupby(\"SK_ID_PREV\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = pd.DataFrame({\n",
    "    \"AMT_BALANCE\": credit_card.groupby(\"SK_ID_PREV\").AMT_BALANCE.mean(),\n",
    "    \"SK_DPD\":      credit_card.groupby(\"SK_ID_PREV\").SK_DPD.max(),\n",
    "    \"SK_DPD_DEF\":  credit_card.groupby(\"SK_ID_PREV\").SK_DPD_DEF.max(),\n",
    "    \"N\":           credit_card.groupby(\"SK_ID_PREV\").count().iloc[:,0]\n",
    "})\n",
    "\n",
    "merge_df = temp.join(merge_df)\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = credit_card.drop(\"SK_ID_CURR\", axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.reset_index()\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_credit\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "merged_cols = ['credit_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:08<00:00,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "prev_app[\"no_credit\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null = prev_app[col].notnull()\n",
    "    median = prev_app[not_null][col].median()\n",
    "    prev_app[col] = prev_app[col].fillna(median)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Misc clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null in prev_app: 19985355\n",
      "Number of null in bureau:   0\n"
     ]
    }
   ],
   "source": [
    "### Drop unneeded SK_ID_PREV from prev_app\n",
    "prev_app = prev_app.drop(\"SK_ID_PREV\", axis=1)\n",
    "\n",
    "print(\"Number of null in prev_app:\", sum(prev_app.isnull().sum()))\n",
    "print(\"Number of null in bureau:  \", sum(bureau.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"final_merge\"></a>\n",
    "\n",
    "# [^](#toc) <u>Final Data Prep</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307511, 122)\n",
      "Shape of test: (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "test  = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\",  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into predictors, target, and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train.TARGET\n",
    "train_x = train.drop([\"TARGET\"], axis=1)\n",
    "\n",
    "test_id = test.SK_ID_CURR\n",
    "test_x  = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full    = pd.concat([train_x, test_x])\n",
    "train_N = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"final_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing values</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = fillna_cat(full)\n",
    "full = fillna_num(full)\n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_app = pd.get_dummies(prev_app)\n",
    "bureau   = pd.get_dummies(bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get categorical features\n",
    "data_cats = [col for col in full.columns if full[col].dtype == 'object']\n",
    "\n",
    "# Factorize the dataframe\n",
    "full = factorize_df(full, data_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Previous Application with full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df      = prev_app.groupby('SK_ID_CURR').mean()\n",
    "merge_df[\"N\"] = prev_app.groupby('SK_ID_CURR').count().iloc[:,0]\n",
    "merged_cols   = ['p_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "full = full.merge(right=merge_df.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231/231 [03:40<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"no_prev_app\"] = full[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null  = full[col].notnull()\n",
    "    median    = full[not_null][col].median()\n",
    "    full[col] = full[col].fillna(median)    \n",
    "    \n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Bureau with full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average Values for all bureau features \n",
    "merge_df         = bureau.groupby('SK_ID_CURR').mean()\n",
    "merge_df['N']    = bureau.groupby('SK_ID_CURR').count().iloc[:,0]\n",
    "merged_cols = ['b_' + f_ for f_ in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "full = full.merge(right=merge_df.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:49<00:00,  1.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"no_bureau\"] = full[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null  = full[col].notnull()\n",
    "    median    = full[not_null][col].median()\n",
    "    full[col] = full[col].fillna(median)    \n",
    "\n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = full.drop(\"SK_ID_CURR\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:07<00:00, 54.50it/s]\n"
     ]
    }
   ],
   "source": [
    "num_cols = [col for col in full.columns if (full[col].dtype != object and \"nan\" not in col)]\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = full[num_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index\n",
    "\n",
    "lam = 0.15\n",
    "\n",
    "for feat in tqdm(skewed_features):\n",
    "#     full[feat].dtype == int\n",
    "    temp = full[feat].unique()\n",
    "    if len(temp) > 4:\n",
    "        full[feat] = boxcox1p(full[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split full back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = full[:train_N]\n",
    "test_x = full[train_N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed data look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for purchase of shares (margin lending)</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for the purchase of equipment</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for working capital replenishment</th>\n",
       "      <th>b_CREDIT_TYPE_Microloan</th>\n",
       "      <th>b_CREDIT_TYPE_Mobile operator loan</th>\n",
       "      <th>b_CREDIT_TYPE_Mortgage</th>\n",
       "      <th>b_CREDIT_TYPE_Real estate loan</th>\n",
       "      <th>b_CREDIT_TYPE_Unknown type of loan</th>\n",
       "      <th>b_N</th>\n",
       "      <th>no_bureau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.008065</td>\n",
       "      <td>39.601640</td>\n",
       "      <td>23.729390</td>\n",
       "      <td>38.592338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.602594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.845784</td>\n",
       "      <td>48.372758</td>\n",
       "      <td>25.455739</td>\n",
       "      <td>47.264738</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.820334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.676485</td>\n",
       "      <td>32.548972</td>\n",
       "      <td>18.354869</td>\n",
       "      <td>32.548972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.548972</td>\n",
       "      <td>37.814328</td>\n",
       "      <td>24.579359</td>\n",
       "      <td>37.472327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.820334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.934081</td>\n",
       "      <td>41.243367</td>\n",
       "      <td>23.178612</td>\n",
       "      <td>41.243367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0                   0            0             0                0   \n",
       "1                   0            1             0                1   \n",
       "2                   1            0             1                0   \n",
       "3                   0            1             0                0   \n",
       "4                   0            0             0                0   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0           0.0         35.008065   39.601640    23.729390        38.592338   \n",
       "1           0.0         36.845784   48.372758    25.455739        47.264738   \n",
       "2           0.0         28.676485   32.548972    18.354869        32.548972   \n",
       "3           0.0         32.548972   37.814328    24.579359        37.472327   \n",
       "4           0.0         31.934081   41.243367    23.178612        41.243367   \n",
       "\n",
       "   NAME_TYPE_SUITE    ...      \\\n",
       "0         0.000000    ...       \n",
       "1         0.730463    ...       \n",
       "2         0.000000    ...       \n",
       "3         0.000000    ...       \n",
       "4         0.000000    ...       \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for purchase of shares (margin lending)  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for the purchase of equipment  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for working capital replenishment  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   b_CREDIT_TYPE_Microloan  b_CREDIT_TYPE_Mobile operator loan  \\\n",
       "0                      0.0                                 0.0   \n",
       "1                      0.0                                 0.0   \n",
       "2                      0.0                                 0.0   \n",
       "3                      0.0                                 0.0   \n",
       "4                      0.0                                 0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Mortgage  b_CREDIT_TYPE_Real estate loan  \\\n",
       "0                     0.0                             0.0   \n",
       "1                     0.0                             0.0   \n",
       "2                     0.0                             0.0   \n",
       "3                     0.0                             0.0   \n",
       "4                     0.0                             0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Unknown type of loan       b_N  no_bureau  \n",
       "0                                 0.0  2.602594          0  \n",
       "1                                 0.0  1.820334          0  \n",
       "2                                 0.0  1.194318          0  \n",
       "3                                 0.0  1.820334          1  \n",
       "4                                 0.0  0.730463          0  \n",
       "\n",
       "[5 rows x 407 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "\n",
    "# [^](#toc) <u>Models </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sban's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds.\n",
      "[200]\tvalid_0's auc: 0.739047\n",
      "[400]\tvalid_0's auc: 0.753712\n",
      "[600]\tvalid_0's auc: 0.764681\n",
      "[800]\tvalid_0's auc: 0.770134\n",
      "[1000]\tvalid_0's auc: 0.772733\n",
      "[1200]\tvalid_0's auc: 0.774141\n",
      "[1400]\tvalid_0's auc: 0.775041\n",
      "[1600]\tvalid_0's auc: 0.775742\n",
      "[1800]\tvalid_0's auc: 0.776154\n",
      "[2000]\tvalid_0's auc: 0.776323\n",
      "[2200]\tvalid_0's auc: 0.776499\n",
      "[2400]\tvalid_0's auc: 0.77658\n",
      "Early stopping, best iteration is:\n",
      "[2367]\tvalid_0's auc: 0.776621\n",
      "Training took 544 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=17)\n",
    "lgb_train = lgb.Dataset(data=train_x, label=train_y)\n",
    "lgb_eval  = lgb.Dataset(data=val_x, label=val_y)\n",
    "\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 0 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "\n",
    "start = time.time()\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval, early_stopping_rounds=150, verbose_eval=200)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_id,\n",
    "    \"TARGET\": predictions\n",
    "}).to_csv(\"../submissions/remove_skew.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
