{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "# <u>Table of Contents</u>\n",
    "1.) [TODO](#todo)  \n",
    "2.) [Imports](#imports)  \n",
    "3.) [Load data](#load)  \n",
    "4.) [Bureau](#bureau)  \n",
    "5.) [Bureau Balance](#bureau_bal)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 5.1.) [Merge into Bureau](#merge_bureau_bal)  \n",
    "6.) [Previous Application](#prev_app)  \n",
    "7.) [POS CASH balance](#pos_cash)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 7.1.) [Missing values](#pos_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 7.2.) [Merge into Previous Application](#merge_pos_cash)  \n",
    "8.) [Installment Payments](#install_pay)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 8.1.) [Missing values](#install_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 8.2.) [Merge into Previous Application](#merge_install_pay)  \n",
    "9.) [Credit Card Balance](#credit)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 9.1.) [Missing values](#credit_nan)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 9.2.) [Merge into Previous Application](#merge_credit)  \n",
    "10.) [Misc clean up](#clean_up)  \n",
    "11.) [Final Data Prep](#final_merge)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 11.1.) [Missing values](#final_nan)  \n",
    "12.) [Modeling](#models)  \n",
    "13.) [Predictions](#predictions)  \n",
    "14.) [Save file to CSV](#save)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"todo\"></a>\n",
    "\n",
    "# [^](#toc) <u>TODO</u>\n",
    "\n",
    "- Fix skew on columns\n",
    "- Tinker with the best way to replace missing values (dropping cols?)\n",
    "- Look for outliers\n",
    "- Merge db together\n",
    "- Include timeline relatoinships like MONTHS_BALANCE\n",
    "- Tune model parameters\n",
    "- Address [this](https://www.kaggle.com/c/home-credit-default-risk/discussion/57248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"imports\"></a>\n",
    "\n",
    "# [^](#toc) <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Time keeper\n",
    "import time\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modeling imports\n",
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "### Removes warnings from output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "def fillna_num(df):\n",
    "    missing_cols = [col for col in df.columns if any(df[col].isnull()) and df[col].dtype != object]\n",
    "    for col in missing_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def fillna_cat(df):\n",
    "    for col in [col for col in df if df[col].dtype==object]:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "def factorize_df(df, cats):\n",
    "    for col in cats:\n",
    "        df[col], _ = pd.factorize(df[col])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"load\"></a>\n",
    "\n",
    "# [^](#toc) <u>Data Path</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of bureau: (1716428, 17)\n",
      "Shape of prev_app: (1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/home_default/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"bureau\"></a>\n",
    "\n",
    "# [^](#toc) <u>Bureau</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau   = pd.read_csv(DATA_PATH + \"bureau.csv\")\n",
    "\n",
    "print(\"Shape of bureau:\",    bureau.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau = fillna_num(bureau)\n",
    "bureau = fillna_cat(bureau)\n",
    "\n",
    "sum(bureau.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bureau_bal\"></a>\n",
    "\n",
    "# [^](#toc) <u>Bureau Balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of bureau_balance: (27299925, 3)\n",
      "\n",
      "Columns of bureau_balance:\n",
      "SK_ID_BUREAU --- MONTHS_BALANCE --- STATUS\n"
     ]
    }
   ],
   "source": [
    "bureau_balance = pd.read_csv(DATA_PATH + \"bureau_balance.csv\")\n",
    "print(\"Shape of bureau_balance:\",  bureau_balance.shape)\n",
    "\n",
    "print(\"\\nColumns of bureau_balance:\")\n",
    "print(\" --- \".join(bureau_balance.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_bureau_bal\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Bureau</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup bureau balance - get dummies\n",
    "merge_df = get_dummies(bureau_balance, [\"STATUS\"])\n",
    "\n",
    "merge_df = merge_df.drop([\"MONTHS_BALANCE\", \"STATUS\"], axis=1)\n",
    "\n",
    "# prep for merge\n",
    "merge_df = merge_df.groupby(\"SK_ID_BUREAU\").sum()\n",
    "\n",
    "### Add the max number of months\n",
    "merge_df[\"max_months\"] = bureau_balance.groupby(\"SK_ID_BUREAU\")[\"MONTHS_BALANCE\"].max()\n",
    "\n",
    "### Remember added columns\n",
    "merged_cols = ['bur_bal_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "# Merge\n",
    "bureau = bureau.merge(right=merge_df.reset_index(), how='left', on='SK_ID_BUREAU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau[\"no_bureau_bal\"] = bureau[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "bureau[merged_cols]     = bureau[merged_cols].fillna(0)\n",
    "sum(bureau.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"prev_app\"></a>\n",
    "\n",
    "# [^](#toc) <u>Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_app = pd.read_csv(DATA_PATH + \"previous_application.csv\")\n",
    "\n",
    "print(\"Shape of prev_app:\",  prev_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prev_nan\"></a>\n",
    "\n",
    "### [^](#toc) Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_app = fillna_num(prev_app)\n",
    "prev_app = fillna_cat(prev_app)\n",
    "\n",
    "sum(prev_app.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"pos_cash\"></a>\n",
    "\n",
    "# [^](#toc) <u>POS CASH balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pcb: (10001358, 8)\n",
      "\n",
      "Columns of pcb:\n",
      "SK_ID_PREV --- SK_ID_CURR --- MONTHS_BALANCE --- CNT_INSTALMENT --- CNT_INSTALMENT_FUTURE --- NAME_CONTRACT_STATUS --- SK_DPD --- SK_DPD_DEF\n"
     ]
    }
   ],
   "source": [
    "pcb = pd.read_csv(DATA_PATH + \"POS_CASH_balance.csv\")\n",
    "print(\"Shape of pcb:\",  pcb.shape)\n",
    "\n",
    "print(\"\\nColumns of pcb:\")\n",
    "print(\" --- \".join(pcb.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pos_nan\"></a>\n",
    "\n",
    "### [^](#toc) Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"CNT_INSTALMENT\", \"CNT_INSTALMENT_FUTURE\"):\n",
    "    pcb[col] = pcb[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcb = pcb.drop(pcb[pcb.NAME_CONTRACT_STATUS.isin([\"XNA\", \"Canceled\"])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = pcb[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "merge_df = get_dummies(merge_df, [\"NAME_CONTRACT_STATUS\"])\n",
    "merge_df = merge_df.drop(\"NAME_CONTRACT_STATUS\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_pos_cash\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep for merge\n",
    "count    = merge_df.groupby(\"SK_ID_PREV\").count()\n",
    "merge_df = merge_df.groupby(\"SK_ID_PREV\").sum().reset_index()\n",
    "merge_df[\"N\"] = list(count.iloc[:,0])\n",
    "\n",
    "# Add the median values.  MONTHS_BALANCE will be added as the max\n",
    "right    = pcb.drop([\"SK_ID_CURR\", \"MONTHS_BALANCE\"], axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")\n",
    "\n",
    "### Add the max number of months\n",
    "merge_df[\"max_months\"] = pcb.groupby(\"SK_ID_PREV\").MONTHS_BALANCE.max()\n",
    "\n",
    "merged_cols = ['pos_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "# Merge\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 1/13 [00:01<00:14,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 2/13 [00:02<00:13,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 3/13 [00:03<00:12,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 4/13 [00:04<00:10,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 5/13 [00:05<00:09,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 6/13 [00:07<00:08,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 7/13 [00:07<00:06,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 8/13 [00:08<00:05,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 9/13 [00:09<00:04,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 10/13 [00:10<00:03,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 11/13 [00:10<00:01,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 12/13 [00:11<00:00,  1.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 13/13 [00:12<00:00,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app[\"no_pcb\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null      = prev_app[col].notnull()\n",
    "    mode          = prev_app[not_null][col].mode().iloc[0]\n",
    "    prev_app[col] = prev_app[col].fillna(mode)    \n",
    "    \n",
    "sum(prev_app.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"install_pay\"></a>\n",
    "\n",
    "# [^](#toc) <u>Installment Payments</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of install_pay: (13605401, 8)\n",
      "\n",
      "Columns of install_pay:\n",
      "SK_ID_PREV --- SK_ID_CURR --- NUM_INSTALMENT_VERSION --- NUM_INSTALMENT_NUMBER --- DAYS_INSTALMENT --- DAYS_ENTRY_PAYMENT --- AMT_INSTALMENT --- AMT_PAYMENT\n"
     ]
    }
   ],
   "source": [
    "install_pay = pd.read_csv(DATA_PATH + \"installments_payments.csv\")\n",
    "print(\"Shape of install_pay:\",  install_pay.shape)\n",
    "\n",
    "print(\"\\nColumns of install_pay:\")\n",
    "print(\" --- \".join(install_pay.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing values</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"DAYS_ENTRY_PAYMENT\", \"AMT_PAYMENT\"):\n",
    "    install_pay[col + \"_nan\"] = install_pay[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "    install_pay[col] = install_pay[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install_pay[\"AMT_MISSING\"] = install_pay[\"AMT_INSTALMENT\"] - install_pay[\"AMT_PAYMENT\"]\n",
    "temp = install_pay.groupby(\"SK_ID_PREV\")[\"AMT_MISSING\"]\n",
    "\n",
    "merge_df = pd.DataFrame({\n",
    "    \"INSTALL_missing_max\": temp.max(),\n",
    "    \"INSTALL_missing_min\": temp.min(),\n",
    "    \"INSTALL_missing_med\": temp.median(),\n",
    "    \"INSTALL_payment_nan\": install_pay.groupby(\"SK_ID_PREV\")[\"AMT_PAYMENT_nan\"].sum(),\n",
    "    \"INSTALL_N\":           temp.count()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = install_pay.drop(\"SK_ID_CURR\", axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.reset_index()\n",
    "\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")\n",
    "merged_cols = merge_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_install_pay\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 1/14 [00:04<01:01,  4.75s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 2/14 [00:05<00:34,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 3/14 [00:06<00:25,  2.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 4/14 [00:07<00:19,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 5/14 [00:08<00:15,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 6/14 [00:09<00:12,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 7/14 [00:10<00:10,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 8/14 [00:11<00:08,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 9/14 [00:12<00:06,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 10/14 [00:14<00:05,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 11/14 [00:16<00:04,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 12/14 [00:17<00:02,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 13/14 [00:17<00:01,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 14/14 [00:18<00:00,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app[\"no_install\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null      = prev_app[col].notnull()\n",
    "    mode          = prev_app[not_null][col].mode().iloc[0]\n",
    "    prev_app[col] = prev_app[col].fillna(mode)    \n",
    "    \n",
    "sum(prev_app.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"credit\"></a>\n",
    "\n",
    "# [^](#toc) <u>Credit Card Balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of credit_card: (3840312, 23)\n",
      "\n",
      "Columns of credit_card:\n",
      "SK_ID_PREV --- SK_ID_CURR --- MONTHS_BALANCE --- AMT_BALANCE --- AMT_CREDIT_LIMIT_ACTUAL --- AMT_DRAWINGS_ATM_CURRENT --- AMT_DRAWINGS_CURRENT --- AMT_DRAWINGS_OTHER_CURRENT --- AMT_DRAWINGS_POS_CURRENT --- AMT_INST_MIN_REGULARITY --- AMT_PAYMENT_CURRENT --- AMT_PAYMENT_TOTAL_CURRENT --- AMT_RECEIVABLE_PRINCIPAL --- AMT_RECIVABLE --- AMT_TOTAL_RECEIVABLE --- CNT_DRAWINGS_ATM_CURRENT --- CNT_DRAWINGS_CURRENT --- CNT_DRAWINGS_OTHER_CURRENT --- CNT_DRAWINGS_POS_CURRENT --- CNT_INSTALMENT_MATURE_CUM --- NAME_CONTRACT_STATUS --- SK_DPD --- SK_DPD_DEF\n"
     ]
    }
   ],
   "source": [
    "credit_card = pd.read_csv(DATA_PATH + \"credit_card_balance.csv\")\n",
    "print(\"Shape of credit_card:\",  credit_card.shape)\n",
    "\n",
    "print(\"\\nColumns of credit_card:\")\n",
    "print(\" --- \".join(credit_card.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"credit_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing Values and Outliers</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [00:01<00:11,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [00:02<00:10,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [00:04<00:08,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [00:06<00:08,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [00:08<00:06,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [00:09<00:04,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [00:10<00:03,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [00:11<00:01,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [00:13<00:00,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "### Remove outliers\n",
    "# Gets indices with outlier values\n",
    "temp = credit_card[credit_card.NAME_CONTRACT_STATUS.isin([\"Refused\", \"Approved\"])].index\n",
    "\n",
    "# Drops outlier values\n",
    "credit_card = credit_card.drop(temp, axis=0)\n",
    "\n",
    "# ------------------------------\n",
    "#### Fill in missing values\n",
    "cols = [\n",
    "        \"AMT_DRAWINGS_ATM_CURRENT\", \"AMT_DRAWINGS_OTHER_CURRENT\", \"AMT_DRAWINGS_POS_CURRENT\", \n",
    "        \"AMT_INST_MIN_REGULARITY\", \"AMT_PAYMENT_CURRENT\", \"CNT_DRAWINGS_ATM_CURRENT\", \n",
    "        \"CNT_DRAWINGS_OTHER_CURRENT\", \"CNT_DRAWINGS_POS_CURRENT\", \"CNT_INSTALMENT_MATURE_CUM\"\n",
    "]\n",
    "for col in tqdm(cols):\n",
    "    not_null = credit_card[col].notnull()\n",
    "    mode = float(credit_card[not_null][col].mode())\n",
    "    credit_card[col] = credit_card[col].fillna(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = credit_card[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "temp = get_dummies(temp, [\"NAME_CONTRACT_STATUS\"])\n",
    "temp = temp.drop(\"NAME_CONTRACT_STATUS\", axis=1)\n",
    "temp = temp.groupby(\"SK_ID_PREV\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = pd.DataFrame({\n",
    "    \"mean_AMT_BALANCE\": credit_card.groupby(\"SK_ID_PREV\").AMT_BALANCE.mean(),\n",
    "    \"max_SK_DPD\":      credit_card.groupby(\"SK_ID_PREV\").SK_DPD.max(),\n",
    "    \"max_SK_DPD_DEF\":  credit_card.groupby(\"SK_ID_PREV\").SK_DPD_DEF.max(),\n",
    "    \"N\":           credit_card.groupby(\"SK_ID_PREV\").count().iloc[:,0]\n",
    "})\n",
    "\n",
    "merge_df = temp.join(merge_df)\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = credit_card.drop(\"SK_ID_CURR\", axis=1).groupby(\"SK_ID_PREV\").median().reset_index()\n",
    "merge_df = merge_df.reset_index()\n",
    "merge_df = merge_df.merge(right=right, how=\"left\", on=\"SK_ID_PREV\").set_index(\"SK_ID_PREV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_credit\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "merged_cols = ['credit_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 1/29 [00:04<02:11,  4.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 2/29 [00:04<01:05,  2.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 3/29 [00:05<00:43,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 4/29 [00:05<00:32,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 5/29 [00:05<00:25,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 6/29 [00:05<00:21,  1.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 7/29 [00:05<00:17,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 8/29 [00:05<00:15,  1.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 9/29 [00:06<00:13,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 10/29 [00:06<00:11,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 11/29 [00:06<00:10,  1.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 12/29 [00:06<00:09,  1.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 13/29 [00:06<00:08,  1.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 14/29 [00:06<00:07,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 15/29 [00:07<00:06,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 16/29 [00:07<00:05,  2.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 17/29 [00:07<00:05,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 18/29 [00:07<00:04,  2.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 19/29 [00:07<00:04,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 20/29 [00:08<00:03,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 21/29 [00:08<00:03,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 22/29 [00:08<00:02,  2.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 23/29 [00:08<00:02,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 24/29 [00:08<00:01,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 25/29 [00:08<00:01,  2.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 26/29 [00:09<00:01,  2.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 27/29 [00:09<00:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 28/29 [00:09<00:00,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_app[\"no_credit\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null = prev_app[col].notnull()\n",
    "    median = prev_app[not_null][col].median()\n",
    "    prev_app[col] = prev_app[col].fillna(median)    \n",
    "    \n",
    "sum(prev_app.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"clean_up\"></a>\n",
    "\n",
    "# [^](#toc) <u>Misc clean up</u>\n",
    "\n",
    "### Drop identification columns\n",
    "\n",
    "Maybe I shouldn't?  Not all the information may be passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null in prev_app: 0\n",
      "Number of null in bureau:   0\n"
     ]
    }
   ],
   "source": [
    "### Drop unneeded SK_ID_PREV from prev_app\n",
    "# prev_app = prev_app.drop(\"SK_ID_PREV\", axis=1)\n",
    "# bureau   = bureau.drop(\"SK_ID_BUREAU\", axis=1)\n",
    "\n",
    "print(\"Number of null in prev_app:\", sum(prev_app.isnull().sum()))\n",
    "print(\"Number of null in bureau:  \", sum(bureau.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers\n",
    "\n",
    "bureau.CREDIT_ACTIVE.value_counts()\n",
    "\n",
    "    Closed      1079273\n",
    "    Active       630607\n",
    "    Sold           6527\n",
    "    Bad debt         21\n",
    "    \n",
    "Maybe this row should stay?  Merge with Sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau = bureau.drop(bureau[bureau.CREDIT_ACTIVE == \"Bad debt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_app = pd.get_dummies(prev_app)\n",
    "bureau   = pd.get_dummies(bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"final_merge\"></a>\n",
    "\n",
    "# [^](#toc) <u>Final Data Prep</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307511, 122)\n",
      "Shape of test: (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "test  = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\",  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into predictors, target, and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train.TARGET\n",
    "train_x = train.drop([\"TARGET\"], axis=1)\n",
    "\n",
    "test_id = test.SK_ID_CURR\n",
    "test_x  = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full    = pd.concat([train_x, test_x])\n",
    "train_N = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"final_nan\"></a>\n",
    "\n",
    "### [^](#toc) <u>Missing values</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = fillna_cat(full)\n",
    "full = fillna_num(full)\n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get categorical features\n",
    "data_cats = [col for col in full.columns if full[col].dtype == 'object']\n",
    "\n",
    "# Factorize the dataframe\n",
    "full = factorize_df(full, data_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Previous Application with full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df      = prev_app.groupby('SK_ID_CURR').mean()\n",
    "merge_df[\"N\"] = prev_app.groupby('SK_ID_CURR').count().iloc[:,0]\n",
    "merged_cols   = ['p_' + col for col in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "full = full.merge(right=merge_df.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/223 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/223 [00:03<13:27,  3.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2/223 [00:04<08:24,  2.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 3/223 [00:05<06:44,  1.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 4/223 [00:06<05:49,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/223 [00:07<05:22,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 6/223 [00:08<04:58,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 7/223 [00:09<04:43,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 8/223 [00:10<04:30,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 9/223 [00:11<04:22,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 10/223 [00:12<04:15,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 11/223 [00:12<04:09,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 12/223 [00:13<04:05,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 13/223 [00:14<04:01,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 14/223 [00:15<03:57,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 15/223 [00:17<03:58,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 16/223 [00:18<03:55,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 17/223 [00:19<03:52,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 18/223 [00:20<03:49,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 19/223 [00:21<03:47,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 20/223 [00:22<03:45,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 21/223 [00:23<03:45,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 22/223 [00:24<03:45,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 23/223 [00:25<03:45,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 24/223 [00:27<03:44,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 25/223 [00:28<03:42,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 26/223 [00:29<03:40,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 27/223 [00:30<03:37,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 28/223 [00:30<03:35,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 29/223 [00:31<03:33,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 30/223 [00:32<03:31,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 31/223 [00:33<03:29,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 32/223 [00:34<03:28,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 33/223 [00:35<03:26,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 34/223 [00:36<03:24,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 35/223 [00:37<03:22,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 36/223 [00:38<03:20,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 37/223 [00:39<03:18,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 38/223 [00:40<03:17,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 39/223 [00:41<03:15,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 40/223 [00:42<03:14,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 41/223 [00:43<03:12,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 42/223 [00:44<03:11,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 43/223 [00:45<03:09,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 44/223 [00:46<03:08,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 45/223 [00:47<03:06,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 46/223 [00:48<03:05,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 47/223 [00:49<03:04,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 48/223 [00:50<03:02,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 49/223 [00:51<03:01,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 50/223 [00:52<03:00,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 51/223 [00:53<02:58,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 52/223 [00:53<02:57,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 53/223 [00:54<02:56,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 54/223 [00:55<02:55,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 55/223 [00:56<02:53,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 56/223 [00:57<02:52,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 57/223 [00:58<02:51,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 58/223 [00:59<02:50,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 59/223 [01:00<02:48,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 60/223 [01:01<02:47,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 61/223 [01:02<02:46,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 62/223 [01:03<02:45,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 63/223 [01:04<02:43,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 64/223 [01:05<02:42,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 65/223 [01:06<02:41,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 66/223 [01:07<02:40,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 67/223 [01:08<02:39,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 68/223 [01:09<02:37,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 69/223 [01:10<02:36,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 70/223 [01:11<02:35,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 71/223 [01:12<02:34,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 72/223 [01:13<02:33,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 73/223 [01:14<02:32,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 74/223 [01:15<02:31,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 75/223 [01:16<02:30,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 76/223 [01:17<02:29,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 77/223 [01:18<02:28,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 78/223 [01:19<02:27,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 79/223 [01:20<02:27,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 80/223 [01:21<02:26,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 81/223 [01:23<02:25,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 82/223 [01:24<02:24,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 83/223 [01:25<02:23,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 84/223 [01:26<02:22,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 85/223 [01:27<02:21,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 86/223 [01:28<02:20,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 87/223 [01:29<02:19,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 88/223 [01:30<02:18,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 89/223 [01:30<02:16,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 90/223 [01:31<02:15,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 91/223 [01:32<02:14,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 92/223 [01:33<02:13,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 93/223 [01:34<02:12,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 94/223 [01:35<02:10,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 95/223 [01:36<02:10,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 96/223 [01:37<02:08,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 97/223 [01:38<02:07,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 98/223 [01:39<02:06,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 99/223 [01:40<02:05,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 100/223 [01:41<02:05,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 101/223 [01:42<02:03,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 102/223 [01:43<02:03,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 103/223 [01:44<02:01,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 104/223 [01:45<02:00,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 105/223 [01:46<01:59,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 106/223 [01:47<01:58,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 107/223 [01:48<01:57,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 108/223 [01:49<01:56,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 109/223 [01:50<01:55,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 110/223 [01:52<01:55,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 111/223 [01:53<01:54,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 112/223 [01:54<01:53,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 113/223 [01:55<01:52,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 114/223 [01:56<01:51,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 115/223 [01:57<01:50,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 116/223 [01:58<01:49,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 117/223 [01:59<01:48,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 118/223 [02:00<01:47,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 119/223 [02:01<01:46,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 120/223 [02:02<01:44,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 121/223 [02:03<01:43,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 122/223 [02:04<01:42,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 123/223 [02:05<01:41,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 124/223 [02:06<01:40,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 125/223 [02:07<01:39,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 126/223 [02:08<01:38,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 127/223 [02:09<01:38,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 128/223 [02:10<01:37,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 129/223 [02:11<01:36,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 130/223 [02:12<01:35,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 131/223 [02:13<01:33,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 132/223 [02:14<01:32,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 133/223 [02:15<01:31,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 134/223 [02:16<01:30,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 135/223 [02:17<01:29,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 136/223 [02:18<01:28,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 137/223 [02:19<01:27,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 138/223 [02:20<01:26,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 139/223 [02:21<01:25,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 140/223 [02:22<01:24,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 141/223 [02:23<01:23,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 142/223 [02:24<01:22,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 143/223 [02:25<01:21,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 144/223 [02:26<01:20,  1.02s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 145/223 [02:27<01:19,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 146/223 [02:28<01:18,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 147/223 [02:29<01:17,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 148/223 [02:30<01:16,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 149/223 [02:31<01:15,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 150/223 [02:32<01:14,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 151/223 [02:33<01:13,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 152/223 [02:34<01:12,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 153/223 [02:35<01:11,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 154/223 [02:36<01:10,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 155/223 [02:37<01:09,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 156/223 [02:38<01:08,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 157/223 [02:39<01:06,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 158/223 [02:40<01:05,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 159/223 [02:41<01:04,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 160/223 [02:42<01:03,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 161/223 [02:43<01:02,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 162/223 [02:44<01:01,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 163/223 [02:45<01:00,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 164/223 [02:46<00:59,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 165/223 [02:47<00:58,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 166/223 [02:48<00:57,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 167/223 [02:49<00:56,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 168/223 [02:50<00:55,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 169/223 [02:51<00:54,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 170/223 [02:52<00:53,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 171/223 [02:53<00:52,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 172/223 [02:54<00:51,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 173/223 [02:55<00:50,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 174/223 [02:56<00:49,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 175/223 [02:57<00:48,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 176/223 [02:58<00:47,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 177/223 [02:59<00:46,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 178/223 [03:00<00:45,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 179/223 [03:01<00:44,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 180/223 [03:02<00:43,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 181/223 [03:03<00:42,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 182/223 [03:04<00:41,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 183/223 [03:05<00:40,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 184/223 [03:07<00:39,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 185/223 [03:08<00:38,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 186/223 [03:09<00:37,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 187/223 [03:10<00:36,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 188/223 [03:11<00:35,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 189/223 [03:12<00:34,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 190/223 [03:13<00:33,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 191/223 [03:15<00:32,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 192/223 [03:16<00:31,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 193/223 [03:17<00:30,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 194/223 [03:18<00:29,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 195/223 [03:19<00:28,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 196/223 [03:20<00:27,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 197/223 [03:21<00:26,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 198/223 [03:22<00:25,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 199/223 [03:23<00:24,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 200/223 [03:24<00:23,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 201/223 [03:25<00:22,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 202/223 [03:26<00:21,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 203/223 [03:27<00:20,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 204/223 [03:28<00:19,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 205/223 [03:29<00:18,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 206/223 [03:31<00:17,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 207/223 [03:32<00:16,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 208/223 [03:33<00:15,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 209/223 [03:34<00:14,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 210/223 [03:35<00:13,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 211/223 [03:36<00:12,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 212/223 [03:37<00:11,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 213/223 [03:38<00:10,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 214/223 [03:39<00:09,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 215/223 [03:40<00:08,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 216/223 [03:41<00:07,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 217/223 [03:42<00:06,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 218/223 [03:43<00:05,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 219/223 [03:44<00:04,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 220/223 [03:45<00:03,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 221/223 [03:46<00:02,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 222/223 [03:47<00:01,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 223/223 [03:48<00:00,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"no_prev_app\"] = full[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null  = full[col].notnull()\n",
    "    median    = full[not_null][col].median()\n",
    "    full[col] = full[col].fillna(median)    \n",
    "    \n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Bureau with full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Values for all bureau features \n",
    "merge_df         = bureau.groupby('SK_ID_CURR').mean().sort_index()\n",
    "merge_df['N']    = bureau.groupby('SK_ID_CURR').count().sort_index().iloc[:,0]\n",
    "\n",
    "### Add the debt to overdue ratio\n",
    "right = (bureau.groupby(\"SK_ID_CURR\")['AMT_CREDIT_SUM_DEBT'].sum() /\n",
    "         bureau.groupby(\"SK_ID_CURR\")['AMT_CREDIT_SUM_OVERDUE'].sum() ).sort_index()\n",
    "merge_df[\"debt_to_overdue\"] = right\n",
    "\n",
    "### Add the debt to overdue ratio\n",
    "right = (bureau.groupby(\"SK_ID_CURR\")['AMT_CREDIT_SUM_DEBT'].sum() /\n",
    "         bureau.groupby(\"SK_ID_CURR\")['AMT_CREDIT_SUM'].sum() ).sort_index()\n",
    "merge_df[\"debt_to_credit\"] = right\n",
    "\n",
    "merged_cols = ['b_' + f_ for f_ in merge_df.columns]\n",
    "merge_df.columns = merged_cols\n",
    "\n",
    "full = full.merge(right=merge_df.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/47 [00:05<03:50,  5.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/47 [00:06<02:15,  3.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 3/47 [00:07<01:42,  2.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 4/47 [00:07<01:25,  2.00s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 5/47 [00:09<01:15,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 6/47 [00:09<01:08,  1.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 7/47 [00:10<01:02,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 8/47 [00:12<00:58,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 9/47 [00:13<00:55,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 10/47 [00:14<00:52,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 11/47 [00:15<00:49,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 12/47 [00:16<00:47,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 13/47 [00:17<00:45,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 14/47 [00:18<00:43,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 15/47 [00:19<00:41,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 16/47 [00:20<00:39,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 17/47 [00:21<00:37,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 18/47 [00:22<00:35,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 19/47 [00:23<00:34,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 20/47 [00:24<00:32,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 21/47 [00:25<00:31,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 22/47 [00:26<00:29,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 23/47 [00:27<00:28,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 24/47 [00:28<00:27,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 25/47 [00:29<00:25,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 26/47 [00:30<00:24,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 27/47 [00:31<00:23,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 28/47 [00:32<00:21,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 29/47 [00:33<00:20,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 30/47 [00:34<00:19,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 31/47 [00:35<00:18,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 32/47 [00:36<00:17,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 33/47 [00:37<00:15,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 34/47 [00:38<00:14,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 35/47 [00:39<00:13,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 36/47 [00:40<00:12,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 37/47 [00:41<00:11,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 38/47 [00:42<00:10,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 39/47 [00:43<00:08,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 40/47 [00:44<00:07,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 41/47 [00:45<00:06,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 42/47 [00:46<00:05,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 43/47 [00:47<00:04,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 44/47 [00:48<00:03,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 45/47 [00:49<00:02,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 46/47 [00:50<00:01,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 47/47 [00:51<00:00,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"no_bureau\"] = full[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in tqdm(merged_cols):\n",
    "    not_null  = full[col].notnull()\n",
    "    median    = full[not_null][col].median()\n",
    "    full[col] = full[col].fillna(median)    \n",
    "\n",
    "sum(full.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop SK_ID_CURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = full.drop(\"SK_ID_CURR\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split full back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = full[:train_N]\n",
    "test_x = full[train_N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed data look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for purchase of shares (margin lending)</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for the purchase of equipment</th>\n",
       "      <th>b_CREDIT_TYPE_Loan for working capital replenishment</th>\n",
       "      <th>b_CREDIT_TYPE_Microloan</th>\n",
       "      <th>b_CREDIT_TYPE_Mobile operator loan</th>\n",
       "      <th>b_CREDIT_TYPE_Mortgage</th>\n",
       "      <th>b_CREDIT_TYPE_Real estate loan</th>\n",
       "      <th>b_CREDIT_TYPE_Unknown type of loan</th>\n",
       "      <th>b_N</th>\n",
       "      <th>no_bureau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0                   0            0             0                0   \n",
       "1                   0            1             0                1   \n",
       "2                   1            0             1                0   \n",
       "3                   0            1             0                0   \n",
       "4                   0            0             0                0   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          202500.0    406597.5      24700.5         351000.0   \n",
       "1             0          270000.0   1293502.5      35698.5        1129500.0   \n",
       "2             0           67500.0    135000.0       6750.0         135000.0   \n",
       "3             0          135000.0    312682.5      29686.5         297000.0   \n",
       "4             0          121500.0    513000.0      21865.5         513000.0   \n",
       "\n",
       "   NAME_TYPE_SUITE    ...      \\\n",
       "0                0    ...       \n",
       "1                1    ...       \n",
       "2                0    ...       \n",
       "3                0    ...       \n",
       "4                0    ...       \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for purchase of shares (margin lending)  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for the purchase of equipment  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Loan for working capital replenishment  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   b_CREDIT_TYPE_Microloan  b_CREDIT_TYPE_Mobile operator loan  \\\n",
       "0                      0.0                                 0.0   \n",
       "1                      0.0                                 0.0   \n",
       "2                      0.0                                 0.0   \n",
       "3                      0.0                                 0.0   \n",
       "4                      0.0                                 0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Mortgage  b_CREDIT_TYPE_Real estate loan  \\\n",
       "0                     0.0                             0.0   \n",
       "1                     0.0                             0.0   \n",
       "2                     0.0                             0.0   \n",
       "3                     0.0                             0.0   \n",
       "4                     0.0                             0.0   \n",
       "\n",
       "   b_CREDIT_TYPE_Unknown type of loan  b_N  no_bureau  \n",
       "0                                 0.0  8.0          0  \n",
       "1                                 0.0  4.0          0  \n",
       "2                                 0.0  2.0          0  \n",
       "3                                 0.0  4.0          1  \n",
       "4                                 0.0  1.0          0  \n",
       "\n",
       "[5 rows x 392 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"models\"></a>\n",
    "\n",
    "# [^](#toc) <u>Models </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sban's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds.\n",
      "[200]\tvalid_0's auc: 0.738903\n",
      "[400]\tvalid_0's auc: 0.755505\n",
      "[600]\tvalid_0's auc: 0.76779\n",
      "[800]\tvalid_0's auc: 0.773027\n",
      "[1000]\tvalid_0's auc: 0.775646\n",
      "[1200]\tvalid_0's auc: 0.777186\n",
      "[1400]\tvalid_0's auc: 0.778163\n",
      "[1600]\tvalid_0's auc: 0.778696\n",
      "[1800]\tvalid_0's auc: 0.779073\n",
      "[2000]\tvalid_0's auc: 0.77933\n",
      "[2200]\tvalid_0's auc: 0.779568\n",
      "[2400]\tvalid_0's auc: 0.779646\n",
      "Early stopping, best iteration is:\n",
      "[2265]\tvalid_0's auc: 0.779686\n",
      "Training took 557 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "# Maybe change the size of the test size?\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=17)\n",
    "lgb_train = lgb.Dataset(data=train_x, label=train_y)\n",
    "lgb_eval  = lgb.Dataset(data=val_x, label=val_y)\n",
    "\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "          'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 0 ,\n",
    "          'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "          'min_split_gain':.01, 'min_child_weight':1}\n",
    "\n",
    "start = time.time()\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval, early_stopping_rounds=150, verbose_eval=200)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"predictions\"></a>\n",
    "\n",
    "# [^](#toc) <u>Predictions</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"save\"></a>\n",
    "\n",
    "# [^](#toc) <u>Save file to CSV</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_id,\n",
    "    \"TARGET\": predictions\n",
    "}).to_csv(\"../submissions/same_filled_nan.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
