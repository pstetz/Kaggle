{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score 79.904%\n",
    "\n",
    "Huge thank you to [Minsuk Heo](https://github.com/minsuk-heo) ([his work](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb)) and [Yassine Ghouzam](https://www.kaggle.com/yassineghouzam) ([his work](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling))!\n",
    "\n",
    "A lot of this work was inspired by them\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/pbezuhov/git/Kaggle/data/titanic/train.csv')\n",
    "test  = pd.read_csv('/Users/pbezuhov/git/Kaggle/data/titanic/test.csv')\n",
    "\n",
    "full  = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_N = len(train)\n",
    "del train, test\n",
    "\n",
    "full = full.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pulling the title information out of people's name (like mr, mrs, dr, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full['Title'] = full['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 1, \"Mlle\": 1, \"Mme\": 1, \"Ms\": 3,\n",
    "                 \"Master\": 2, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3 ,\"Countess\": 3,\n",
    "                 \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "\n",
    "full['Title'] = full['Title'].map(title_mapping)\n",
    "    \n",
    "# delete unnecessary feature from dataset\n",
    "full.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the categorical sex column into a numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "\n",
    "full['Sex'] = full['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"Age\"].fillna(full.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "#### The most embarked station is S, so it's safe to fill in nan values with S\n",
    "full['Embarked'] = full['Embarked'].fillna('S')\n",
    "\n",
    "# fill missing Fare with median fare for each Pclass\n",
    "test[\"Fare\"].fillna(training_data.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "full['Cabin'] = full['Cabin'].str[:1]\n",
    "full[\"Cabin\"].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cabin_mapping = {\"None\": 0, \"C\": 1, \"B\": 2, \"D\": 3, \"E\": 4, \"A\": 5, \"F\": 5, \"G\": 5, \"T\": 5}\n",
    "\n",
    "full['Cabin'] = full['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ticket column seems to have no information so I drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = full.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = dataset[:train_len]\n",
    "test = dataset[train_len:]\n",
    "test.drop(labels=[\"Survived\"],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81111111 0.79775281 0.83146067 0.82022472 0.84269663 0.80898876\n",
      " 0.83146067 0.80898876 0.83146067 0.86516854]\n",
      "\n",
      "Average is ...\n",
      "0.8249313358302123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "k_fold = KFold(shuffle=True, random_state=1)\n",
    "\n",
    "pipeline = make_pipeline(Imputer(), SVC())\n",
    "\n",
    "train_y = train_data['Survived']\n",
    "train_x = train_data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(model, train_x, train_y, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)\n",
    "print(\"\\nAverage is ...\")\n",
    "print(sum(score) / len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(Imputer(), SVC())\n",
    "pipeline.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = test_data.drop(\"PassengerId\", axis=1)\n",
    "prediction = pipeline.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": prediction\n",
    "    })\n",
    "\n",
    "submission.to_csv('/Users/pbezuhov/git/Kaggle/submissions/titanic/10_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
