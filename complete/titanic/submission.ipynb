{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score: \n",
    "\n",
    "Huge thank you to [Minsuk Heo](https://github.com/minsuk-heo) ([his work](https://github.com/minsuk-heo/kaggle-titanic/blob/master/titanic-solution.ipynb)) and [Yassine Ghouzam](https://www.kaggle.com/yassineghouzam) ([his work](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling))!\n",
    "\n",
    "A lot of this work was inspired by them\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/pbezuhov/git/Kaggle/data/titanic/train.csv')\n",
    "test  = pd.read_csv('/Users/pbezuhov/git/Kaggle/data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Outlier detection curtesy of Yassine who in turn was motivated by the Tukey method\n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        Q1 = np.percentile(df[col], 25) # 1st quartile (25%)\n",
    "        Q3 = np.percentile(df[col],75)  # 3rd quartile (75%)\n",
    "        IQR = Q3 - Q1                   # Interquartile range (IQR)\n",
    "    \n",
    "        outlier_step = 1.5 * IQR\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    \n",
    "    return multiple_outliers   \n",
    "\n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "outliers_to_drop = detect_outliers(train, 2, [\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n",
    "\n",
    "train = train.drop(outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat train and test data for easier manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full  = pd.concat([train, test], axis=0).reset_index(drop=True)\n",
    "\n",
    "train_N = len(train)\n",
    "del train, test\n",
    "\n",
    "full = full.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Title Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pulling the title information out of people's name (like mr, mrs, dr, etc)\n",
    "full['Title'] = full['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 1, \"Mlle\": 1, \"Mme\": 1, \"Ms\": 3,\n",
    "                 \"Master\": 2, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3 ,\"Countess\": 3,\n",
    "                 \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "\n",
    "full['Title'] = full['Title'].map(title_mapping)\n",
    "    \n",
    "# delete unnecessary feature from dataset\n",
    "full.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#### Age\n",
    "index_NaN_age = list(full[\"Age\"][full[\"Age\"].isnull()].index)\n",
    "for i in index_NaN_age :\n",
    "    age_med = full[\"Age\"].median()\n",
    "    age_pred = full[\"Age\"][\n",
    "                            ((full['SibSp'] == full.iloc[i][\"SibSp\"]) &\n",
    "                             (full['Parch'] == full.iloc[i][\"Parch\"]) &\n",
    "                             (full['Pclass'] == full.iloc[i][\"Pclass\"]))\n",
    "                          ].median()\n",
    "    if not np.isnan(age_pred) :\n",
    "        full['Age'].iloc[i] = age_pred\n",
    "    else :\n",
    "        full['Age'].iloc[i] = age_med\n",
    "\n",
    "#### Embarked\n",
    "# The most embarked station is S, so it's safe to fill in nan values with S\n",
    "full['Embarked'] = full['Embarked'].fillna('S')\n",
    "\n",
    "#### Fare\n",
    "# fill missing Fare with median fare for each Pclass\n",
    "full[\"Fare\"].fillna(full.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n",
    "\n",
    "#### Cabin\n",
    "full['Cabin'] = full['Cabin'].str[:1]\n",
    "full[\"Cabin\"].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a family size column\n",
    "\n",
    "Thanks again to Minsuk and Yassine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a family size descriptor from SibSp and Parch\n",
    "full[\"Fsize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
    "\n",
    "# Create new feature of family size\n",
    "full['Single'] = full['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "full['SmallF'] = full['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n",
    "full['MedF']   = full['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "full['LargeF'] = full['Fsize'].map(lambda s: 1 if s >= 5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply log to Fare to reduce skewness distribution\n",
    "full[\"Fare\"] = full[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title</th>\n",
       "      <th>Fsize</th>\n",
       "      <th>Single</th>\n",
       "      <th>SmallF</th>\n",
       "      <th>MedF</th>\n",
       "      <th>LargeF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked      Fare  Parch  PassengerId  Pclass     Sex  SibSp  \\\n",
       "0  22.0  None        S  1.981001      0            1       3    male      1   \n",
       "1  38.0     C        C  4.266662      0            2       1  female      1   \n",
       "2  26.0  None        S  2.070022      0            3       3  female      0   \n",
       "3  35.0     C        S  3.972177      0            4       1  female      1   \n",
       "4  35.0  None        S  2.085672      0            5       3    male      0   \n",
       "\n",
       "   Survived  Title  Fsize  Single  SmallF  MedF  LargeF  \n",
       "0       0.0      0      2       0       1     0       0  \n",
       "1       1.0      1      2       0       1     0       0  \n",
       "2       1.0      1      1       1       0     0       0  \n",
       "3       1.0      1      2       0       1     0       0  \n",
       "4       0.0      0      1       1       0     0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n",
    "# def ticket_prefix(x):\n",
    "#     if not x.isdigit() :\n",
    "#         return x.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0] #Take prefix\n",
    "#     else:\n",
    "#         return \"X\"\n",
    "\n",
    "# full[\"Ticket\"] = full.Ticket.map(ticket_prefix)\n",
    "full.drop(labels=[\"Ticket\"], axis=1, inplace=True)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to indicator values Title and Embarked \n",
    "full = pd.get_dummies(full, columns = [\"Title\", \"Sex\", \"Pclass\"])\n",
    "full = pd.get_dummies(full, columns = [\"Embarked\"], prefix=\"Em\")\n",
    "full = pd.get_dummies(full, columns = [\"Cabin\"],    prefix=\"Ca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data back into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train = full[:train_N]\n",
    "test = full[train_N:]\n",
    "test.drop(labels=[\"Survived\"], axis=1, inplace=True)\n",
    "\n",
    "del full, train_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Survived\"] = train[\"Survived\"].astype(int)\n",
    "train_y = train[\"Survived\"]\n",
    "train_x = train.drop(labels=[\"Survived\", \"PassengerId\"], axis=1)\n",
    "test_x  = test.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massive amounts of model imports\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, learning_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cross validate model with Kfold stratified cross val\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META MODELING\n",
    "\n",
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 112 candidates, totalling 1120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 712 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 1120 out of 1120 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='random'),\n",
       "          learning_rate=0.1, n_estimators=2, random_state=7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "adaDTC = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "ada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[1,2],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "gsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsadaDTC.fit(train_x, train_y)\n",
    "\n",
    "gsadaDTC.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    }
   ],
   "source": [
    "ExtC = ExtraTreesClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsExtC.fit(train_x, train_y)\n",
    "\n",
    "ExtC_best = gsExtC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsExtC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsRFC.fit(train_x, train_y)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "gb_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100,150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsGBC.fit(train_x, train_y)\n",
    "\n",
    "GBC_best = gsGBC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsGBC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "gsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(train_x, train_y)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Survived_RFC  = pd.Series(RFC_best.predict( test_x), name=\"RFC\")\n",
    "test_Survived_ExtC = pd.Series(ExtC_best.predict(test_x), name=\"ExtC\")\n",
    "test_Survived_SVMC = pd.Series(SVMC_best.predict(test_x), name=\"SVC\")\n",
    "test_Survived_AdaC = pd.Series(ada_best.predict( test_x), name=\"Ada\")\n",
    "test_Survived_GBC  = pd.Series(GBC_best.predict( test_x), name=\"GBC\")\n",
    "\n",
    "\n",
    "# Concatenate all classifier results\n",
    "ensemble_results = pd.concat([\n",
    "                                test_Survived_RFC,\n",
    "                                test_Survived_ExtC,\n",
    "                                test_Survived_AdaC,\n",
    "                                test_Survived_GBC,\n",
    "                                test_Survived_SVMC\n",
    "                             ],axis=1)\n",
    "\n",
    "votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n",
    "('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Predicting and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = votingC.predict(test_x)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "                            \"PassengerId\": test.PassengerId,\n",
    "                            \"Survived\": predictions\n",
    "                            })\n",
    "\n",
    "predictions.to_csv(\"../../submissions/titanic.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "\n",
    "Taken from Yassine's code.  I think these plots are very interesting\n",
    "\n",
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "g = plot_learning_curve(gsRFC.best_estimator_,\"RF mearning curves\",X_train,Y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,Y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",X_train,Y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,Y_train,cv=kfold)\n",
    "g = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",X_train,Y_train,cv=kfold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
