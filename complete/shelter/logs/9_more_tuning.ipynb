{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score: 11.32097\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (26729, 10)\n",
      "test shape: (11456, 8)\n",
      "Earliest train time: 2013-10-01 09:31:00 - Latest train time: 2016-02-21 19:17:00\n",
      "Earliest test time: 2013-10-01 10:44:00 - Latest test time: 2016-02-21 18:37:00\n"
     ]
    }
   ],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "train = pd.read_csv(\"../../data/shelter/train.csv\", parse_dates=['DateTime'], date_parser=dateparse)\n",
    "test  = pd.read_csv(\"../../data/shelter/test.csv\", parse_dates=['DateTime'], date_parser=dateparse)\n",
    "\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)\n",
    "\n",
    "print(\"Earliest train time:\", min(train.DateTime), \"- Latest train time:\", max(train.DateTime))\n",
    "print(\"Earliest test time:\",  min(test.DateTime),  \"- Latest test time:\",  max(test.DateTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop row with missing Sex value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(train[train.SexuponOutcome.isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat([train, test])\n",
    "train_N = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"weekday\"] = full.DateTime.map(lambda x: x.weekday())\n",
    "full[\"year\"]    = full.DateTime.map(lambda x: x.year)\n",
    "full[\"month\"]   = full.DateTime.map(lambda x: x.month)\n",
    "full[\"hour\"]    = full.DateTime.map(lambda x: x.hour)\n",
    "\n",
    "full[\"is_weekend\"] = full.weekday.map(lambda x: int(x in [5, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column: time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"night\"]   = full.hour.map(lambda x: int(x > 5  and x < 11))\n",
    "full[\"morning\"] = full.hour.map(lambda x: int(x > 10 and x < 16))\n",
    "full[\"midday\"]  = full.hour.map(lambda x: int(x > 15 and x < 20))\n",
    "full[\"lateday\"] = full.hour.map(lambda x: int(x > 19 or  x < 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create columns sex and is_netured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_neut(x):\n",
    "    if x is np.nan:\n",
    "        return np.nan\n",
    "    elif x == \"Unknown\":\n",
    "        return 2\n",
    "    return int(\"Neutered\" in x or \"Sprayed\" in x)\n",
    "\n",
    "def get_sex(x):\n",
    "    if x is np.nan:\n",
    "        return np.nan\n",
    "    elif x == \"Unknown\":\n",
    "        return 2\n",
    "    return int(\"Male\" in x)\n",
    "\n",
    "full[\"Sex\"] = full.SexuponOutcome.map(get_sex)\n",
    "full[\"isNetured\"] = full.SexuponOutcome.map(get_neut)\n",
    "\n",
    "full = full.drop([\"SexuponOutcome\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgeuponOutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_age(x):\n",
    "    if x is np.nan:\n",
    "        return None\n",
    "    \n",
    "    num, scale = x.split(\" \")\n",
    "    if scale in [\"day\", \"days\"]:\n",
    "        return int(num)\n",
    "    elif scale in [\"week\", \"weeks\"]:\n",
    "        return 7 * int(num)\n",
    "    elif scale in [\"month\", \"months\"]:\n",
    "        return 30 * int(num)\n",
    "    elif scale in [\"year\", \"years\"]:\n",
    "        return 365 * int(num)\n",
    "\n",
    "# This may seem like double variables, but people are weird and may think 100 weeks is a lot younger than 2 years\n",
    "def human_age(x, timescale):\n",
    "    if x is np.nan:\n",
    "        return 0\n",
    "    num, scale = x.split(\" \")\n",
    "    if scale in [timescale, timescale+\"s\"]:\n",
    "        return int(num)\n",
    "    return 0\n",
    "\n",
    "full[\"age_year\"]  = full.AgeuponOutcome.map(lambda x: human_age(x, \"year\"))\n",
    "full[\"age_month\"] = full.AgeuponOutcome.map(lambda x: human_age(x, \"month\"))\n",
    "full[\"age_week\"]  = full.AgeuponOutcome.map(lambda x: human_age(x, \"week\"))\n",
    "full[\"age_day\"]   = full.AgeuponOutcome.map(lambda x: human_age(x, \"day\"))\n",
    "full.AgeuponOutcome = full.AgeuponOutcome.map(format_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in AgeuponOutcome values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full.AgeuponOutcome.fillna(\n",
    "    full.groupby(\"Breed\")[\"AgeuponOutcome\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column: is_baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"is_baby\"] = full.AgeuponOutcome.map(lambda x: int(x < 365))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnimalType mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full.AnimalType = full.AnimalType.map({\"Dog\": 0, \"Cat\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breed\n",
    "\n",
    "### Hair type and isMix\n",
    "\n",
    "Looks at the breed and determines whether the breed is a mix or determine the length of its hair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shorthair_map  = lambda x: 1 if \"Shorthair\" in x else 0\n",
    "mediumhair_map = lambda x: 1 if \"Medium Hair\" in x else 0\n",
    "longhair_map   = lambda x: 1 if \"Longhair\" in x else 0\n",
    "mix_map        = lambda x: 1 if \"Mix\" in x else 0\n",
    "\n",
    "full[\"Shorthair\"]  = full.Breed.map(shorthair_map)\n",
    "full[\"Mediumhair\"] = full.Breed.map(mediumhair_map)\n",
    "full[\"Longhair\"]   = full.Breed.map(longhair_map)\n",
    "full[\"Mix\"]        = full.Breed.map(mix_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column first breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full[\"first_breed\"] = full.Breed.map(lambda x: x.split(\"/\")[0].replace(\" Mix\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breed mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_col_map(df, col, cutoff):\n",
    "    val_counts = df[col].value_counts()\n",
    "    ret = dict()\n",
    "    counter = 0\n",
    "    \n",
    "    for index in val_counts.index:\n",
    "        count = val_counts[index]\n",
    "        if count > cutoff:\n",
    "            ret[index] = counter\n",
    "            counter += 1\n",
    "        else:\n",
    "            ret[index] = counter\n",
    "    return ret\n",
    "\n",
    "breed_map = get_col_map(full, \"Breed\", 300)\n",
    "first_breed_map = get_col_map(full, \"first_breed\", 300)\n",
    "\n",
    "full.Breed       = full.Breed.map(breed_map)\n",
    "full.first_breed = full.first_breed.map(first_breed_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color\n",
    "\n",
    "### Create column: Individual colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue_map  = lambda x: 1 if \"Blue\"      in x else 0\n",
    "black_map = lambda x: 1 if \"White\"     in x else 0\n",
    "white_map = lambda x: 1 if \"White\"     in x else 0\n",
    "brown_map = lambda x: 1 if \"Brown\"     in x else 0\n",
    "tabby_map = lambda x: 1 if \"Tabby\"     in x else 0\n",
    "tan_map   = lambda x: 1 if \"Tan\"       in x else 0\n",
    "red_map   = lambda x: 1 if \"Red\"       in x else 0\n",
    "choc_map  = lambda x: 1 if \"Chocolate\" in x else 0\n",
    "\n",
    "\n",
    "full[\"Blue\"]  = full.Color.map(blue_map)\n",
    "full[\"Black\"] = full.Color.map(black_map)\n",
    "full[\"White\"] = full.Color.map(white_map)\n",
    "full[\"Brown\"] = full.Color.map(brown_map)\n",
    "full[\"Tabby\"] = full.Color.map(tabby_map)\n",
    "full[\"Tan\"]   = full.Color.map(tan_map)\n",
    "full[\"Red\"]   = full.Color.map(red_map)\n",
    "full[\"Choc\"]  = full.Color.map(choc_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular colors are given a numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_map = get_col_map(full, \"Color\", 300)\n",
    "\n",
    "full.Color = full.Color.map(color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "\n",
    "I'm wondering if a missing name is indicative of anything?  Maybe the name is missing because the dog was transfered quickly or spent a little time at the shelter.  Also some outcome's may rely on having documentation of the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_map = lambda x: 0 if x is np.nan else 1\n",
    "\n",
    "full.Name = full.Name.map(name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split full back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>AnimalID</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>OutcomeSubtype</th>\n",
       "      <th>OutcomeType</th>\n",
       "      <th>...</th>\n",
       "      <th>Mix</th>\n",
       "      <th>first_breed</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Black</th>\n",
       "      <th>White</th>\n",
       "      <th>Brown</th>\n",
       "      <th>Tabby</th>\n",
       "      <th>Tan</th>\n",
       "      <th>Red</th>\n",
       "      <th>Choc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.0</td>\n",
       "      <td>A671945</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Return_to_owner</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365.0</td>\n",
       "      <td>A656520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Suffering</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730.0</td>\n",
       "      <td>A686464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>A683430</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>730.0</td>\n",
       "      <td>A667013</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeuponOutcome AnimalID  AnimalType  Breed  Color            DateTime  ID  \\\n",
       "0           365.0  A671945           0     13      5 2014-02-12 18:22:00 NaN   \n",
       "1           365.0  A656520           1      0     30 2013-10-13 12:44:00 NaN   \n",
       "2           730.0  A686464           0      1      9 2015-01-31 12:28:00 NaN   \n",
       "3            21.0  A683430           1      0     31 2014-07-11 19:09:00 NaN   \n",
       "4           730.0  A667013           0     13     12 2013-11-15 12:52:00 NaN   \n",
       "\n",
       "   Name OutcomeSubtype      OutcomeType  ...   Mix  first_breed  Blue  Black  \\\n",
       "0     1            NaN  Return_to_owner  ...     1           20     0      1   \n",
       "1     1      Suffering       Euthanasia  ...     1            0     0      0   \n",
       "2     1         Foster         Adoption  ...     1            1     1      1   \n",
       "3     0        Partner         Transfer  ...     1            0     1      0   \n",
       "4     0        Partner         Transfer  ...     0           20     0      0   \n",
       "\n",
       "   White  Brown  Tabby  Tan  Red  Choc  \n",
       "0      1      1      0    0    0     0  \n",
       "1      0      0      1    0    0     0  \n",
       "2      1      0      0    0    0     0  \n",
       "3      0      0      0    0    0     0  \n",
       "4      0      0      0    1    0     0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = full[:train_N]\n",
    "test = full[train_N:]\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target from predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train.OutcomeType.map({\"Adoption\": 0, \"Transfer\": 1, \"Return_to_owner\": 2, \"Euthanasia\": 3, \"Died\": 4})\n",
    "train_x = train.drop([\"DateTime\", \"OutcomeType\", \"OutcomeSubtype\", \"AnimalID\", \"ID\"], axis=1)\n",
    "\n",
    "test_x = test.drop([\"DateTime\", \"OutcomeType\", \"OutcomeSubtype\", \"AnimalID\", \"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the model\n",
    "\n",
    "Let's try out a few models and see which works best through cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Massive amounts of model imports\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold, learning_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "kfold = StratifiedKFold()\n",
    "\n",
    "def score_model(model):\n",
    "    score = cross_val_score(model, train_x, train_y, cv=kfold, n_jobs=1, scoring=\"accuracy\")\n",
    "    print(score)\n",
    "    print(\"\\nAverage is ...\")\n",
    "    print(sum(score) / len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    "## Extra Trees Classifier\n",
    "\n",
    "### Parameter Search\n",
    "\n",
    "(open Markdown here to see param search history)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "#### Attempt 1:\n",
    "\n",
    "Tried:\n",
    "\n",
    "{\"max_depth\": [None],\n",
    "  \"max_features\": [1, 3, 10],\n",
    "  \"min_samples_split\": [2, 3, 10],\n",
    "  \"min_samples_leaf\": [1, 3, 10],\n",
    "  \"bootstrap\": [False],\n",
    "  \"n_estimators\" :[100,300],\n",
    "  \"criterion\": [\"gini\"]}\n",
    "\n",
    "Best:\n",
    "\n",
    "{'bootstrap': False,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 10,\n",
    " 'min_samples_leaf': 10,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 300}\n",
    " \n",
    "#### Attempt 2:\n",
    " \n",
    "Tried:\n",
    "\n",
    "ex_param_grid = {\n",
    "                  \"max_depth\": [2, 4],\n",
    "                  \"max_features\": [10, 14],\n",
    "                  \"min_samples_split\": [8, 10],\n",
    "                  \"min_samples_leaf\": [3, 8, 10],\n",
    "                  \"n_estimators\" :[80, 100]\n",
    "                }\n",
    "\n",
    "ExtC = ExtraTreesClassifier(max_depth=None, criterion=\"gini\", bootstrap=False,)\n",
    "\n",
    "Best:\n",
    "\n",
    "{'max_depth': 4, 'max_features': 14, 'min_samples_leaf': 8, 'min_samples_split': 10, 'n_estimators': 80}\n",
    "\n",
    "#### Attempt 3:\n",
    "\n",
    "Tried:\n",
    "\n",
    "ex_param_grid = {\n",
    "                  \"max_depth\": [None, 4],\n",
    "                  \"max_features\": [14, 16],\n",
    "                  \"min_samples_split\": [10, 12],\n",
    "                  \"min_samples_leaf\": [7, 8],\n",
    "                  \"n_estimators\" :[80, 90]\n",
    "                }\n",
    "\n",
    "ExtC = ExtraTreesClassifier(max_depth=None, criterion=\"gini\", bootstrap=False,)\n",
    "\n",
    "Best:\n",
    "\n",
    "{'max_depth': None, 'max_features': 14, 'min_samples_leaf': 8, 'min_samples_split': 10, 'n_estimators': 80}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.653247530679\n",
      "{'max_depth': None, 'max_features': 14, 'min_samples_leaf': 8, 'min_samples_split': 10, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "## Search grid for optimal parameters\n",
    "ex_param_grid = {\n",
    "                  \"max_depth\": [None, 4],\n",
    "                  \"max_features\": [14, 16],\n",
    "                  \"min_samples_split\": [10, 12],\n",
    "                  \"min_samples_leaf\": [7, 8],\n",
    "                  \"n_estimators\" :[80, 90]\n",
    "                }\n",
    "\n",
    "ExtC = ExtraTreesClassifier(max_depth=None, criterion=\"gini\", bootstrap=False,)\n",
    "\n",
    "gsExtC = GridSearchCV(ExtC, param_grid=ex_param_grid, cv=kfold, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "gsExtC.fit(train_x, train_y)\n",
    "\n",
    "# Best score\n",
    "print(gsExtC.best_score_)\n",
    "print(gsExtC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65536977  0.64769921  0.64679466]\n",
      "\n",
      "Average is ...\n",
      "0.649954545986\n"
     ]
    }
   ],
   "source": [
    "# etc_model = ExtraTreesClassifier(\n",
    "#                                     bootstrap=False,\n",
    "#                                     criterion=\"gini\",\n",
    "#                                     max_depth=None,\n",
    "#                                     max_features=14,\n",
    "#                                     min_samples_leaf=8,\n",
    "#                                     min_samples_split=10,\n",
    "#                                     n_estimators=80\n",
    "#                                 )\n",
    "# etc_model.fit(train_x, train_y)\n",
    "# score_model(etc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    "## Random Forest Classifier\n",
    "\n",
    "### Parameter Search\n",
    "\n",
    "(open Markdown here to see param search history)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "#### Attempt 1:\n",
    "\n",
    "Tried:\n",
    "\n",
    "{\"max_depth\": [None],\n",
    "  \"max_features\": [1, 3, 10],\n",
    "  \"min_samples_split\": [2, 3, 10],\n",
    "  \"min_samples_leaf\": [1, 3, 10],\n",
    "  \"bootstrap\": [False],\n",
    "  \"n_estimators\" :[100,300],\n",
    "  \"criterion\": [\"gini\"]}\n",
    "\n",
    "Best:\n",
    "\n",
    "{'bootstrap': False,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 3,\n",
    " 'min_samples_leaf': 10,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 300}\n",
    " \n",
    "#### Attempt 2:\n",
    "\n",
    "Tried:\n",
    "\n",
    "rf_param_grid = {\n",
    "                    \"max_depth\": [None, 1, 2],\n",
    "                    \"max_features\": [3, 5],\n",
    "                    \"min_samples_split\": [8, 10],\n",
    "                    \"min_samples_leaf\": [8, 10],\n",
    "                    \"n_estimators\" :[100,300],\n",
    "                }\n",
    "\n",
    "RFC = RandomForestClassifier(bootstrap=False, criterion=\"gini\")\n",
    "\n",
    "Best:\n",
    "\n",
    "{'max_depth': None, 'max_features': 5, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 300}\n",
    "\n",
    "#### Attempt 3:\n",
    "\n",
    "Tried:\n",
    "\n",
    "rf_param_grid = {\n",
    "                    \"max_features\": [5, 7],\n",
    "                    \"min_samples_split\": [6, 8],\n",
    "                    \"min_samples_leaf\": [6, 8],\n",
    "                    \"n_estimators\" :[200, 300, 350],\n",
    "                }\n",
    "\n",
    "RFC = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "\n",
    "Best:\n",
    "\n",
    "{'max_features': 7, 'min_samples_leaf': 6, 'min_samples_split': 8, 'n_estimators': 350}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6528733912\n",
      "{'max_features': 7, 'min_samples_leaf': 6, 'min_samples_split': 8, 'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\n",
    "                    \"max_features\": [5, 7],\n",
    "                    \"min_samples_split\": [6, 8],\n",
    "                    \"min_samples_leaf\": [6, 8],\n",
    "                    \"n_estimators\" :[200, 300, 350],\n",
    "                }\n",
    "\n",
    "RFC = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_depth=None)\n",
    "\n",
    "gsRFC = GridSearchCV(RFC, param_grid=rf_param_grid, cv=kfold, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "gsRFC.fit(train_x, train_y)\n",
    "\n",
    "# Best score\n",
    "print(gsRFC.best_score_)\n",
    "print(gsRFC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64728987  0.64320988  0.64264062]\n",
      "\n",
      "Average is ...\n",
      "0.644380120913\n"
     ]
    }
   ],
   "source": [
    "# rfc_model = RandomForestClassifier(\n",
    "#                                     bootstrap=False,\n",
    "#                                     criterion=\"gini\",\n",
    "#                                     max_depth=None,\n",
    "#                                     max_features=5,\n",
    "#                                     min_samples_leaf=8,\n",
    "#                                     min_samples_split=8,\n",
    "#                                     n_estimators=300\n",
    "#                                   )\n",
    "# rfc_model.fit(train_x, train_y)\n",
    "# score_model(rfc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Gradient Boost Classifier\n",
    "\n",
    "### Parameter Search\n",
    "\n",
    "(open Markdown here to see param search history)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "#### Attempt 1:\n",
    "\n",
    "Tried:\n",
    "\n",
    "{'loss' : [\"deviance\"],\n",
    "  'n_estimators' : [100,200,300],\n",
    "  'learning_rate': [0.1, 0.05, 0.01],\n",
    "  'max_depth': [4, 8],\n",
    "  'min_samples_leaf': [100,150],\n",
    "  'max_features': [0.3, 0.1] \n",
    "  }\n",
    "\n",
    "Best:\n",
    "\n",
    "{'learning_rate': 0.05,\n",
    " 'loss': 'deviance',\n",
    " 'max_depth': 8,\n",
    " 'max_features': 0.3,\n",
    " 'min_samples_leaf': 100,\n",
    " 'n_estimators': 100}\n",
    " \n",
    "#### Attempt 2:\n",
    "\n",
    "Tried:\n",
    " \n",
    "gb_param_grid = {\n",
    "                    'n_estimators' : [100, 120],\n",
    "                    'max_depth': [8, 10],\n",
    "                    'min_samples_leaf': [80, 100],\n",
    "                    'max_features': [8, 10]\n",
    "                }\n",
    "\n",
    "GBC = GradientBoostingClassifier(loss=\"deviance\", learning_rate=0.04)\n",
    "\n",
    "Best:\n",
    "\n",
    "{'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 80, 'n_estimators': 120}\n",
    "\n",
    "#### Attempt 3:\n",
    "\n",
    "Tried:\n",
    " \n",
    "gb_param_grid = {\n",
    "                    'n_estimators': [120, 200],\n",
    "                    'max_depth': [None, 10],\n",
    "                    'min_samples_leaf': [70, 80, 90],\n",
    "                    'max_features': [10, 12]\n",
    "                }\n",
    "\n",
    "GBC = GradientBoostingClassifier(loss=\"deviance\", learning_rate=0.04)\n",
    "\n",
    "Best:\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 236.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668026040108\n",
      "{'max_depth': 10, 'max_features': 12, 'min_samples_leaf': 70, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "## Search grid for optimal parameters\n",
    "gb_param_grid = {\n",
    "                    'n_estimators': [120, 200],\n",
    "                    'max_depth': [None, 10],\n",
    "                    'min_samples_leaf': [70, 80, 90],\n",
    "                    'max_features': [10, 12]\n",
    "                }\n",
    "\n",
    "GBC = GradientBoostingClassifier(loss=\"deviance\", learning_rate=0.04)\n",
    "\n",
    "gsGBC = GridSearchCV(GBC, param_grid=gb_param_grid, cv=kfold, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "gsGBC.fit(train_x, train_y)\n",
    "\n",
    "# Best score\n",
    "print(gsGBC.best_score_)\n",
    "print(gsGBC.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66389855  0.66262626  0.66284944]\n",
      "\n",
      "Average is ...\n",
      "0.663124753078\n"
     ]
    }
   ],
   "source": [
    "# gbc_model = GradientBoostingClassifier(\n",
    "#                                           loss = \"deviance\",\n",
    "#                                           learning_rate = 0.05,\n",
    "#                                           n_estimators = 120,\n",
    "#                                           max_depth = 10,\n",
    "#                                           min_samples_leaf = 80,\n",
    "#                                           max_features = 10\n",
    "#                                       )\n",
    "# gbc_model.fit(train_x, train_y)\n",
    "# score_model(gbc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ada Boost Classifier\n",
    "\n",
    "### Parameter Search\n",
    "\n",
    "(open Markdown here to see param search history)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "#### Attempt 1:\n",
    "\n",
    "tried:\n",
    "\n",
    "{\n",
    "\"n_estimators\": [1, 50, 100],\n",
    "\"learning_rate\": [0.05, 0.1, 0.2],\n",
    "\"base_estimator\\__max_depth\": [None, 2, 4],\n",
    "\"base_estimator\\__splitter\" :   [\"best\", \"random\"],\n",
    "\"base_estimator\\__criterion\" : [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "best:\n",
    "\n",
    "{'base_estimator\\__criterion': 'entropy', 'base_estimator\\__max_depth': 4, 'base_estimator\\__splitter': 'random', 'learning_rate': 0.1, 'n_estimators': 100}\n",
    "\n",
    "#### Attempt 2:\n",
    "\n",
    "tried:\n",
    "\n",
    "ada_param_grid = {\n",
    "                    \"n_estimators\": [50, 100, 120, 200],\n",
    "                    \"base_estimator__max_depth\": [3, 4, 6],\n",
    "                 }\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=17, splitter=\"random\", criterion=\"entropy\")\n",
    "\n",
    "ADA = AdaBoostClassifier(base_estimator=DTC, learning_rate=0.08)\n",
    "\n",
    "best:\n",
    "\n",
    "{'base_estimator\\__max_depth': 3, 'n_estimators': 120}\n",
    "\n",
    "#### Attempt 2:\n",
    "\n",
    "tried:\n",
    "\n",
    "ada_param_grid = {\n",
    "                    \"n_estimators\": [50, 100, 120, 200],\n",
    "                    \"base_estimator__max_depth\": [3, 4, 6],\n",
    "                 }\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=17, splitter=\"random\", criterion=\"entropy\")\n",
    "\n",
    "ADA = AdaBoostClassifier(base_estimator=DTC, learning_rate=0.08)\n",
    "\n",
    "best:\n",
    "\n",
    "{'base_estimator__max_depth': 3, 'n_estimators': 120}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643482490272\n",
      "{'base_estimator__max_depth': 3, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "## Search grid for optimal parameters\n",
    "ada_param_grid = {\n",
    "                    \"n_estimators\": [110, 120, 130],\n",
    "                    \"base_estimator__max_depth\": [None, 3],\n",
    "                 }\n",
    "\n",
    "DTC = DecisionTreeClassifier(random_state=17, splitter=\"random\", criterion=\"entropy\")\n",
    "ADA = AdaBoostClassifier(base_estimator=DTC, learning_rate=0.08)\n",
    "\n",
    "gsADA = GridSearchCV(ADA, param_grid=ada_param_grid, cv=kfold, scoring=\"accuracy\", verbose=1)\n",
    "\n",
    "gsADA.fit(train_x, train_y)\n",
    "\n",
    "# Best score\n",
    "print(gsADA.best_score_)\n",
    "print(gsADA.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64930984  0.63647587  0.64454923]\n",
      "\n",
      "Average is ...\n",
      "0.64344498084\n"
     ]
    }
   ],
   "source": [
    "# dtc = DecisionTreeClassifier(\n",
    "#                                 random_state=17,\n",
    "#                                 splitter=\"random\",\n",
    "#                                 criterion=\"entropy\",\n",
    "#                                 max_depth=3\n",
    "#                             )\n",
    "\n",
    "# ada_model = AdaBoostClassifier(\n",
    "#                                 base_estimator=dtc,\n",
    "#                                 learning_rate=0.08,\n",
    "#                                 n_estimators=120\n",
    "#                               )\n",
    "\n",
    "# ada_model.fit(train_x, train_y)\n",
    "# score_model(ada_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## XGB\n",
    "\n",
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6539109   0.65162738  0.65229595]\n",
      "\n",
      "Average is ...\n",
      "0.652611409538\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(train_x, train_y)\n",
    "score_model(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## LGBM\n",
    "\n",
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.67197845  0.6657688   0.66879982]\n",
      "\n",
      "Average is ...\n",
      "0.668849024355\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(train_x, train_y)\n",
    "score_model(lgbm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66760184  0.66296296  0.66385989]\n",
      "\n",
      "Average is ...\n",
      "0.664808229623\n"
     ]
    }
   ],
   "source": [
    "etc_model = gsExtC.best_estimator_\n",
    "rfc_model = gsRFC.best_estimator_\n",
    "gbc_model = gsGBC.best_estimator_\n",
    "ada_model = gsADA.best_estimator_\n",
    "\n",
    "model = VotingClassifier(estimators=[\n",
    "                                        (\"ETC\", etc_model),                                    \n",
    "                                        (\"RFC\", rfc_model),\n",
    "                                        (\"GBC\",gbc_model),\n",
    "                                        (\"XGB\", xgb_model),\n",
    "                                        (\"ADA\", ada_model),\n",
    "                                        (\"LGBM\", lgbm_model)\n",
    "                                      ], voting='soft')\n",
    "\n",
    "#### Fit and score model\n",
    "model = model.fit(train_x, train_y)\n",
    "score_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"ID\": test.ID.astype(int),\n",
    "    \"Adoption\": [1 if pred == 0 else 0 for pred in predictions],\n",
    "    \"Died\": [1 if pred == 4 else 0 for pred in predictions],\n",
    "    \"Euthanasia\": [1 if pred == 3 else 0 for pred in predictions],\n",
    "    \"Return_to_owner\": [1 if pred == 2 else 0 for pred in predictions],\n",
    "    \"Transfer\": [1 if pred == 1 else 0 for pred in predictions]\n",
    "}).to_csv('../../submissions/shelter_voting_powerful_tuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
