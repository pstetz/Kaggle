{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score:\n",
    "\n",
    "- Most of this inspiration comes from Kaggle user [Serigine](https://www.kaggle.com/serigne) and his excellent [tutorial](https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard)\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/house_prices/train.csv')\n",
    "test = pd.read_csv('../../data/house_prices/test.csv')\n",
    "\n",
    "train_id = train['Id']\n",
    "test_id = test['Id']\n",
    "\n",
    "train.drop(\"Id\", axis = 1, inplace = True)\n",
    "test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial preprocessing and merging data\n",
    "\n",
    "Removing outliers were determined by an excerpt from the dataset auther\n",
    "\n",
    "    \" Although all known errors were corrected in the data, no observations have been removed due to unusual values  and all final residential sales from the initial data set are included in the data presented with this article. There are five observations that an instructor may wish to remove from the data set before giving it to students (a plot of SALE PRICE versus GR LIV AREA will quickly indicate these points). Three of them are true outliers (Partial Sales that likely donâ€™t represent actual market values) and two of them are simply unusual sales (very large houses priced relatively appropriately). I would recommend removing any houses with more than 4000 square feet from the data set (which eliminates these five unusual observations) before assigning it to students. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove outliers (see analysis notebook)\n",
    "train = train.drop(train[(train['GrLivArea']>4000)].index)\n",
    "\n",
    "# applies log(1+x) to all elements of the column\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "train_N = train.shape[0]\n",
    "train_y = train.SalePrice.values\n",
    "\n",
    "full = pd.concat((train, test)).reset_index(drop=True)\n",
    "full.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#### MODE\n",
    "# Fill these features with their mode, the most commonly occuring value. This is okay since there are a low number of missing values for these features\n",
    "for col in (\"MSZoning\", \"Electrical\", \"KitchenQual\", \n",
    "            \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Functional\")\n",
    "    full[col] = full[col].fillna(full[col].mode()[0])\n",
    "    \n",
    "#### ZERO\n",
    "# Using data description, fill these missing values with 0 \n",
    "for col in (\"GarageYrBlt\", \"GarageArea\", \"GarageCars\", \"BsmtFinSF1\", \n",
    "           \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"MasVnrArea\",\n",
    "           \"BsmtFullBath\", \"BsmtHalfBath\"):\n",
    "    full[col] = full[col].fillna(0)\n",
    "    \n",
    "#### NONE\n",
    "for col in (\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\",\n",
    "           \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n",
    "           \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\",\n",
    "            \"BsmtFinType2\", \"MSSubClass\", \"MasVnrType\"):\n",
    "    full[col] = full[col].fillna(\"None\")\n",
    "    \n",
    "full[\"LotFrontage\"] = full.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = full.drop(['Utilities'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical columns into categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in ('MSSubClass', 'OverallCond', 'YrSold', 'MoSold'):\n",
    "    full[col] = full[col].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quadratic\n",
    "full[\"OverallQual-2\"] = full[\"OverallQual\"] ** 2\n",
    "full[\"GrLivArea-2\"] = full[\"GrLivArea\"] ** 2\n",
    "full[\"GarageCars-2\"] = full[\"GarageCars\"] ** 2\n",
    "full[\"GarageArea-2\"] = full[\"GarageArea\"] ** 2\n",
    "full[\"TotalBsmtSF-2\"] = full[\"TotalBsmtSF\"] ** 2\n",
    "full[\"1stFlrSF-2\"] = full[\"1stFlrSF\"] ** 2\n",
    "full[\"FullBath-2\"] = full[\"FullBath\"] ** 2\n",
    "full[\"TotRmsAbvGrd-2\"] = full[\"TotRmsAbvGrd\"] ** 2\n",
    "full[\"Fireplaces-2\"] = full[\"Fireplaces\"] ** 2\n",
    "full[\"MasVnrArea-2\"] = full[\"MasVnrArea\"] ** 2\n",
    "full[\"BsmtFinSF1-2\"] = full[\"BsmtFinSF1\"] ** 2\n",
    "full[\"LotFrontage-2\"] = full[\"LotFrontage\"] ** 2\n",
    "full[\"WoodDeckSF-2\"] = full[\"WoodDeckSF\"] ** 2\n",
    "full[\"OpenPorchSF-2\"] = full[\"OpenPorchSF\"] ** 2\n",
    "full[\"2ndFlrSF-2\"] = full[\"2ndFlrSF\"] ** 2\n",
    "print(\"Quadratics done!...\")\n",
    "\n",
    "# Cubic\n",
    "full[\"OverallQual-3\"] = full[\"OverallQual\"] ** 3\n",
    "full[\"GrLivArea-3\"] = full[\"GrLivArea\"] ** 3\n",
    "full[\"GarageCars-3\"] = full[\"GarageCars\"] ** 3\n",
    "full[\"GarageArea-3\"] = full[\"GarageArea\"] ** 3\n",
    "full[\"TotalBsmtSF-3\"] = full[\"TotalBsmtSF\"] ** 3\n",
    "full[\"1stFlrSF-3\"] = full[\"1stFlrSF\"] ** 3\n",
    "full[\"FullBath-3\"] = full[\"FullBath\"] ** 3\n",
    "full[\"TotRmsAbvGrd-3\"] = full[\"TotRmsAbvGrd\"] ** 3\n",
    "full[\"Fireplaces-3\"] = full[\"Fireplaces\"] ** 3\n",
    "full[\"MasVnrArea-3\"] = full[\"MasVnrArea\"] ** 3\n",
    "full[\"BsmtFinSF1-3\"] = full[\"BsmtFinSF1\"] ** 3\n",
    "full[\"LotFrontage-3\"] = full[\"LotFrontage\"] ** 3\n",
    "full[\"WoodDeckSF-3\"] = full[\"WoodDeckSF\"] ** 3\n",
    "full[\"OpenPorchSF-3\"] = full[\"OpenPorchSF\"] ** 3\n",
    "full[\"2ndFlrSF-3\"] = full[\"2ndFlrSF\"] ** 3\n",
    "print(\"Cubics done!...\")\n",
    "\n",
    "# Square Root\n",
    "full[\"OverallQual-Sq\"] = np.sqrt(full[\"OverallQual\"])\n",
    "full[\"GrLivArea-Sq\"] = np.sqrt(full[\"GrLivArea\"])\n",
    "full[\"GarageCars-Sq\"] = np.sqrt(full[\"GarageCars\"])\n",
    "full[\"GarageArea-Sq\"] = np.sqrt(full[\"GarageArea\"])\n",
    "full[\"TotalBsmtSF-Sq\"] = np.sqrt(full[\"TotalBsmtSF\"])\n",
    "full[\"1stFlrSF-Sq\"] = np.sqrt(full[\"1stFlrSF\"])\n",
    "full[\"FullBath-Sq\"] = np.sqrt(full[\"FullBath\"])\n",
    "full[\"TotRmsAbvGrd-Sq\"] = np.sqrt(full[\"TotRmsAbvGrd\"])\n",
    "full[\"Fireplaces-Sq\"] = np.sqrt(full[\"Fireplaces\"])\n",
    "full[\"MasVnrArea-Sq\"] = np.sqrt(full[\"MasVnrArea\"])\n",
    "full[\"BsmtFinSF1-Sq\"] = np.sqrt(full[\"BsmtFinSF1\"])\n",
    "full[\"LotFrontage-Sq\"] = np.sqrt(full[\"LotFrontage\"])\n",
    "full[\"WoodDeckSF-Sq\"] = np.sqrt(full[\"WoodDeckSF\"])\n",
    "full[\"OpenPorchSF-Sq\"] = np.sqrt(full[\"OpenPorchSF\"])\n",
    "full[\"2ndFlrSF-Sq\"] = np.sqrt(full[\"2ndFlrSF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encodes all the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(full[col].values)) \n",
    "    full[col] = lbl.transform(list(full[col].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column Total Square Feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full['TotalSF'] = full['TotalBsmtSF'] + full['1stFlrSF'] + full['2ndFlrSF']\n",
    "\n",
    "all_data['BsmtQual'] = all_data['BsmtQual'].map({\"None\":0, \"Fa\":1, \"TA\":2, \"Gd\":3, \"Ex\":4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing skew\n",
    "\n",
    "All of this skew analysis is thanks to Serginne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "numeric_feats = full.dtypes[full.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = full[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "\n",
    "for feat in skewed_features:\n",
    "    full[feat] = boxcox1p(full[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn categorical columns into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.get_dummies(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the merged data back into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = full[:train_N]\n",
    "test = full[train_N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(5, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, train_y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "def rms(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating different models\n",
    "\n",
    "The parameters for each of the models were suggested by Serginne for being very robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to help stack different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1085 (0.0074)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Stacked Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07815719379163877\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "\n",
    "# Predicting train values\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "\n",
    "# Predicting test values\n",
    "stacked_pred = stacked_averaged_models.predict(test.values)\n",
    "stacked_pred = np.expm1(stacked_pred) # exp(x) + 1 (reverses log1p from earlier)\n",
    "\n",
    "print(rmsle_cv(train_y, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07872027124385908\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "model_xgb.fit(train, y_train)\n",
    "\n",
    "# Predicting train values\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "\n",
    "# Predicting test values\n",
    "xgb_pred = model_xgb.predict(test)\n",
    "xgb_pred = np.expm1(xgb_pred) # exp(x) + 1 (reverses log1p from earlier)\n",
    "\n",
    "print(rmsle_cv(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boost Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07307464036005418\n"
     ]
    }
   ],
   "source": [
    "# Fitting\n",
    "model_lgb.fit(train, y_train)\n",
    "\n",
    "# Predicting train values\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "\n",
    "# Predicting test values\n",
    "lgb_pred = model_lgb.predict(test.values)\n",
    "lgb_pred = np.expm1(lgb_pred) # exp(x) + 1 (reverses log1p from earlier)\n",
    "\n",
    "print(rmsle_cv(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    'Id': test_id,\n",
    "    'SalePrice': ensemble\n",
    "})\n",
    "\n",
    "predictions.to_csv('../../submissions/house.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
