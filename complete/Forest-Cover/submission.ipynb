{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns:\n",
      "\n",
      "Numerical columns:\n",
      "Id --- Elevation --- Aspect --- Slope --- Horizontal_Distance_To_Hydrology --- Vertical_Distance_To_Hydrology --- Horizontal_Distance_To_Roadways --- Hillshade_9am --- Hillshade_Noon --- Hillshade_3pm --- Horizontal_Distance_To_Fire_Points --- Wilderness_Area1 --- Wilderness_Area2 --- Wilderness_Area3 --- Wilderness_Area4 --- Soil_Type1 --- Soil_Type2 --- Soil_Type3 --- Soil_Type4 --- Soil_Type5 --- Soil_Type6 --- Soil_Type7 --- Soil_Type8 --- Soil_Type9 --- Soil_Type10 --- Soil_Type11 --- Soil_Type12 --- Soil_Type13 --- Soil_Type14 --- Soil_Type15 --- Soil_Type16 --- Soil_Type17 --- Soil_Type18 --- Soil_Type19 --- Soil_Type20 --- Soil_Type21 --- Soil_Type22 --- Soil_Type23 --- Soil_Type24 --- Soil_Type25 --- Soil_Type26 --- Soil_Type27 --- Soil_Type28 --- Soil_Type29 --- Soil_Type30 --- Soil_Type31 --- Soil_Type32 --- Soil_Type33 --- Soil_Type34 --- Soil_Type35 --- Soil_Type36 --- Soil_Type37 --- Soil_Type38 --- Soil_Type39 --- Soil_Type40 --- Cover_Type\n",
      "\n",
      "Shape of train: (15120, 56)\n",
      "Shape of test: (565892, 55)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../data/Forest-Cover/\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "test  = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "cat_columns = [col for col in train.columns if train[col].dtype == object]\n",
    "print(\"Categorical columns:\")\n",
    "print(\" --- \".join(cat_columns))\n",
    "\n",
    "### Numerical columns\n",
    "num_columns = [col for col in train.columns if train[col].dtype != object]\n",
    "print(\"Numerical columns:\")\n",
    "print(\" --- \".join(num_columns))\n",
    "print()\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\",  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into id, target, and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train[\"Cover_Type\"]\n",
    "train_id = train[\"Id\"]\n",
    "train_x = train.drop([\"Cover_Type\", \"Id\"], axis=1)\n",
    "\n",
    "test_id = test[\"Id\"]\n",
    "test_x  = test.drop(\"Id\", axis=1)\n",
    "\n",
    "full    = pd.concat([train_x, test_x])\n",
    "train_N = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full['HF1'] = abs(full['Horizontal_Distance_To_Hydrology']   + full['Horizontal_Distance_To_Fire_Points'])\n",
    "full['HF2'] = abs(full['Horizontal_Distance_To_Hydrology']   - full['Horizontal_Distance_To_Fire_Points'])\n",
    "full['HR1'] = abs(full['Horizontal_Distance_To_Hydrology']   + full['Horizontal_Distance_To_Roadways'])\n",
    "full['HR2'] = abs(full['Horizontal_Distance_To_Hydrology']   - full['Horizontal_Distance_To_Roadways'])\n",
    "full['FR1'] = abs(full['Horizontal_Distance_To_Fire_Points'] + full['Horizontal_Distance_To_Roadways'])\n",
    "full['FR2'] = abs(full['Horizontal_Distance_To_Fire_Points'] - full['Horizontal_Distance_To_Roadways'])\n",
    "full['ele_vert'] = full.Elevation-full.Vertical_Distance_To_Hydrology\n",
    "\n",
    "full['slope_hyd'] = (full['Horizontal_Distance_To_Hydrology']**2 + full['Vertical_Distance_To_Hydrology']**2)**0.5\n",
    "full[\"slope_hyd\"] = full.slope_hyd.map(lambda x: 0 if np.isinf(x) else x)\n",
    "\n",
    "full['Mean_Amenities'] = (full.Horizontal_Distance_To_Fire_Points +\n",
    "                          full.Horizontal_Distance_To_Hydrology +\n",
    "                          full.Horizontal_Distance_To_Roadways) / 3 \n",
    "full['Mean_Fire_Hyd']  = (full.Horizontal_Distance_To_Fire_Points +\n",
    "                          full.Horizontal_Distance_To_Hydrology) / 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = full[:train_N]\n",
    "test_x  = full[train_N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              ExtraTreesClassifier, VotingClassifier)\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "TAKE_CV = False\n",
    "first_layer_train = pd.DataFrame()\n",
    "first_layer_preds = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees 1\n",
    "\n",
    "This works really well, so I'm going to create a second model with different params and random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc_model_1 = ExtraTreesClassifier(n_estimators=25, criterion='gini',\n",
    "                                   max_depth=None, min_samples_split=2,\n",
    "                                   min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                   max_features='auto', max_leaf_nodes=None,\n",
    "                                   min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                   bootstrap=False, random_state=17)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(etc_model_1, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "etc_model_1.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"ETC1\"] = etc_model_1.predict(train_x)\n",
    "first_layer_preds[\"ETC1\"] = etc_model_1.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc_model_2 = ExtraTreesClassifier(n_estimators=500, criterion='gini',\n",
    "                                   max_depth=None, min_samples_split=2,\n",
    "                                   min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                   max_features='auto', max_leaf_nodes=None,\n",
    "                                   min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                   bootstrap=False, random_state=71)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(etc_model_2, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "etc_model_2.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"ETC2\"] = etc_model_2.predict(train_x)\n",
    "first_layer_preds[\"ETC2\"] = etc_model_2.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model_1 = XGBClassifier(max_depth=4, learning_rate=1,\n",
    "                            n_estimators=100, gamma=0, min_child_weight=1,\n",
    "                            max_delta_step=0, subsample=1, colsample_bytree=0.6,\n",
    "                            colsample_bylevel=1, reg_alpha=3, reg_lambda=3,\n",
    "                            scale_pos_weight=1, base_score=0.5, random_state=17)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(xgb_model_1, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "xgb_model_1.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"XGB1\"] = xgb_model_1.predict(train_x)\n",
    "first_layer_preds[\"XGB1\"] = xgb_model_1.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Model 2\n",
    "\n",
    "This model is taken from [Siddharth Yadav](https://www.kaggle.com/thebrownviking20) and his excellent [kernel](https://www.kaggle.com/thebrownviking20/voting-classifier-for-victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_2 = XGBClassifier(max_depth=20, n_estimators=1000, random_state=71)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(xgb_model_2, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "xgb_model_2.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"XGB2\"] = xgb_model_2.predict(train_x)\n",
    "first_layer_preds[\"XGB2\"] = xgb_model_2.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_model = RandomForestClassifier(n_estimators=25, criterion='gini',\n",
    "                                   max_depth=None, min_samples_split=6,\n",
    "                                   min_samples_leaf=3, min_weight_fraction_leaf=0.0,\n",
    "                                   max_features='auto', max_leaf_nodes=None,\n",
    "                                   min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                   random_state=17)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(rfc_model, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "rfc_model.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"RFC\"] = rfc_model.predict(train_x)\n",
    "first_layer_preds[\"RFC\"] = rfc_model.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model_1  = LGBMClassifier(num_leaves=45, max_depth=7,\n",
    "                              learning_rate=0.3,\n",
    "                              reg_lambda=0.5, reg_alpha=0.5,\n",
    "                              min_split_gain=0.1, min_child_weight=0.5,\n",
    "                              min_data_in_leaf=5,\n",
    "                              feature_fraction=0.5,\n",
    "                              random_state=17)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(lgb_model_1, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "lgb_model_1.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"LGB1\"] = lgb_model_1.predict(train_x)\n",
    "first_layer_preds[\"LGB1\"] = lgb_model_1.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model_2  = LGBMClassifier(num_leaves=70, max_depth=8,\n",
    "                              learning_rate=0.1,\n",
    "                              reg_lambda=1, reg_alpha=1,\n",
    "                              min_split_gain=0.1, min_child_weight=0.5,\n",
    "                              min_data_in_leaf=5,\n",
    "                              feature_fraction=0.3,\n",
    "                              random_state=71)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(lgb_model_2, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "lgb_model_2.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"LGB2\"] = lgb_model_2.predict(train_x)\n",
    "first_layer_preds[\"LGB2\"] = lgb_model_2.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Gradient Boosting 3\n",
    "\n",
    "This model is taken from [Siddharth Yadav](https://www.kaggle.com/thebrownviking20) and his excellent [kernel](https://www.kaggle.com/thebrownviking20/voting-classifier-for-victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_model_3  = LGBMClassifier(n_estimators=2000, max_depth=15, random_state=171)\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(lgb_model_3, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "lgb_model_3.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"LGB3\"] = lgb_model_3.predict(train_x)\n",
    "first_layer_preds[\"LGB3\"] = lgb_model_3.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost 1\n",
    "\n",
    "This model is taken from [Siddharth Yadav](https://www.kaggle.com/thebrownviking20) and his excellent [kernel](https://www.kaggle.com/thebrownviking20/voting-classifier-for-victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_model_1 = AdaBoostClassifier(\n",
    "                ExtraTreesClassifier(n_estimators=500),\n",
    "                n_estimators=250, learning_rate=0.01, algorithm='SAMME', random_state=17\n",
    ")\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(ada_model_1, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "ada_model_1.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"ADA1\"] = ada_model_1.predict(train_x)\n",
    "first_layer_preds[\"ADA1\"] = ada_model_1.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost 2\n",
    "\n",
    "This model is taken from [Siddharth Yadav](https://www.kaggle.com/thebrownviking20) and his excellent [kernel](https://www.kaggle.com/thebrownviking20/voting-classifier-for-victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_model_2 = AdaBoostClassifier(\n",
    "                GradientBoostingClassifier(n_estimators=1000, max_depth=10),\n",
    "                n_estimators=1000, learning_rate=0.01, algorithm=\"SAMME\", random_state=17\n",
    ")\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(ada_model_2, train_x, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "\n",
    "ada_model_2.fit(train_x, train_y)\n",
    "\n",
    "first_layer_train[\"ADA2\"] = ada_model_2.predict(train_x)\n",
    "first_layer_preds[\"ADA2\"] = ada_model_2.predict(test_x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voting_model = SVC()\n",
    "\n",
    "if TAKE_CV:\n",
    "    scores = cross_val_score(voting_model, first_layer_train, train_y, cv=5, verbose=1)\n",
    "    score_mean = round(np.mean(scores), 4)\n",
    "    score_std  = round(np.std(scores), 3)\n",
    "    print(f\"Score is {score_mean} +/- {score_std}\")\n",
    "    \n",
    "voting_model.fit(first_layer_train, train_y)\n",
    "predictions = voting_model.predict(first_layer_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"Cover_Type\": predictions, \"Id\": test_id} )\n",
    "predictions.to_csv(\"../\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
