{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "# <u>Table of Contents</u>\n",
    "1.) [TODO](#todo)  \n",
    "2.) [Imports](#imports)  \n",
    "3.) [Load data](#load)  \n",
    "4.) [Bureau Balance](#bureau_bal)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 4.1.) [Merge into Bureau](#merge_bureau_bal)  \n",
    "5.) [POS CASH balance](#pos_cash)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 5.1.) [Merge into Previous Application](#merge_pos_cash)  \n",
    "6.) [Installment Payments](#install_pay)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 6.1.) [Merge into Previous Application](#merge_install_pay)  \n",
    "7.) [Credit Card Balance](#credit)  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; 7.1.) [Merge into Previous Application](#merge_credit)  \n",
    "8.) [Modeling](#models)  \n",
    "9.) [Save file to CSV](#save)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"todo\"></a>\n",
    "\n",
    "# [^](#toc) <u>TODO</u>\n",
    "\n",
    "- Fix skew on columns\n",
    "- Tinker with the best way to replace missing values (dropping cols?)\n",
    "- Look for outliers\n",
    "- Merge db together\n",
    "- Include timeline relatoinships like MONTHS_BALANCE\n",
    "- Tune model parameters\n",
    "- Address [this](https://www.kaggle.com/c/home-credit-default-risk/discussion/57248)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "\n",
    "# [^](#toc) <u>Imports</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "\n",
    "# [^](#toc) <u>Load data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307511, 123)\n",
      "Shape of test: (48744, 122)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../data/home_default/\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "test  = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "test['is_train'] = 0\n",
    "train['is_train'] = 1\n",
    "\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\",  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(DATA_PATH + \"bureau.csv\")\n",
    "bureau_balance = pd.read_csv(DATA_PATH + \"bureau_balance.csv\")\n",
    "prev_app = pd.read_csv(DATA_PATH + \"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bureau_bal\"></a>\n",
    "\n",
    "# [^](#toc) <u>Bureau Balance</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup bureau balance - get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "bureau_balance = get_dummies(bureau_balance, [\"STATUS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_bureau_bal\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Bureau</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS_0</th>\n",
       "      <th>STATUS_1</th>\n",
       "      <th>STATUS_2</th>\n",
       "      <th>STATUS_3</th>\n",
       "      <th>STATUS_4</th>\n",
       "      <th>STATUS_5</th>\n",
       "      <th>STATUS_C</th>\n",
       "      <th>STATUS_X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001710</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001711</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001712</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              STATUS_0  STATUS_1  STATUS_2  STATUS_3  STATUS_4  STATUS_5  \\\n",
       "SK_ID_BUREAU                                                               \n",
       "5001709              0         0         0         0         0         0   \n",
       "5001710              5         0         0         0         0         0   \n",
       "5001711              3         0         0         0         0         0   \n",
       "5001712             10         0         0         0         0         0   \n",
       "5001713              0         0         0         0         0         0   \n",
       "\n",
       "              STATUS_C  STATUS_X  \n",
       "SK_ID_BUREAU                      \n",
       "5001709             86        11  \n",
       "5001710             48        30  \n",
       "5001711              0         1  \n",
       "5001712              9         0  \n",
       "5001713              0        22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance = bureau_balance.drop([\"MONTHS_BALANCE\", \"STATUS\"], axis=1)\n",
    "\n",
    "# prep for merge\n",
    "bureau_balance = bureau_balance.groupby(\"SK_ID_BUREAU\").sum()\n",
    "\n",
    "# Merge\n",
    "bureau = bureau.merge(right=bureau_balance.reset_index(), how='left', on='SK_ID_BUREAU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new missing values with -1\n",
    "\n",
    "There won't be any effect if we replace NaN with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                      0\n",
       "SK_ID_BUREAU                    0\n",
       "CREDIT_ACTIVE                   0\n",
       "CREDIT_CURRENCY                 0\n",
       "DAYS_CREDIT                     0\n",
       "CREDIT_DAY_OVERDUE              0\n",
       "DAYS_CREDIT_ENDDATE        105553\n",
       "DAYS_ENDDATE_FACT          633653\n",
       "AMT_CREDIT_MAX_OVERDUE    1124488\n",
       "CNT_CREDIT_PROLONG              0\n",
       "AMT_CREDIT_SUM                 13\n",
       "AMT_CREDIT_SUM_DEBT        257669\n",
       "AMT_CREDIT_SUM_LIMIT       591780\n",
       "AMT_CREDIT_SUM_OVERDUE          0\n",
       "CREDIT_TYPE                     0\n",
       "DAYS_CREDIT_UPDATE              0\n",
       "AMT_ANNUITY               1226791\n",
       "STATUS_0                        0\n",
       "STATUS_1                        0\n",
       "STATUS_2                        0\n",
       "STATUS_3                        0\n",
       "STATUS_4                        0\n",
       "STATUS_5                        0\n",
       "STATUS_C                        0\n",
       "STATUS_X                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau[[\"STATUS_0\", \"STATUS_1\", \"STATUS_2\", \"STATUS_3\", \"STATUS_4\", \"STATUS_5\", \"STATUS_C\", \"STATUS_X\"]] = (\n",
    "    bureau[[\"STATUS_0\", \"STATUS_1\", \"STATUS_2\", \"STATUS_3\", \"STATUS_4\", \"STATUS_5\", \"STATUS_C\", \"STATUS_X\"]]\n",
    "        .fillna(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pos_cash\"></a>\n",
    "\n",
    "# [^](#toc) <u>POS CASH balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcb = pd.read_csv(DATA_PATH + \"POS_CASH_balance.csv\")\n",
    "print(\"Shape of pcb:\",  pcb.shape)\n",
    "\n",
    "print(\"\\n{}Columns of pcb:{}\".format(color.UNDERLINE, color.END))\n",
    "print(\" --- \".join(pcb.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"CNT_INSTALMENT\", \"CNT_INSTALMENT_FUTURE\"):\n",
    "    pcb[col] = pcb[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcb = pcb.drop(pcb[pcb.NAME_CONTRACT_STATUS.isin([\"XNA\", \"Canceled\"])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcb = pcb[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "pcb = get_dummies(pcb, [\"NAME_CONTRACT_STATUS\"])\n",
    "pcb = pcb.drop(\"NAME_CONTRACT_STATUS\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_pos_cash\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of merged columns\n",
    "merged_cols = set(pcb.columns)\n",
    "merged_cols.remove(\"SK_ID_PREV\")\n",
    "\n",
    "# prep for merge\n",
    "temp = pcb.groupby(\"SK_ID_PREV\").sum()\n",
    "\n",
    "# Merge\n",
    "prev_app = prev_app.merge(right=temp.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install_pay\"></a>\n",
    "\n",
    "# [^](#toc) <u>Installment Payments</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of install_pay: (13605401, 8)\n",
      "\n",
      "Columns of install_pay:\n",
      "SK_ID_PREV --- SK_ID_CURR --- NUM_INSTALMENT_VERSION --- NUM_INSTALMENT_NUMBER --- DAYS_INSTALMENT --- DAYS_ENTRY_PAYMENT --- AMT_INSTALMENT --- AMT_PAYMENT\n"
     ]
    }
   ],
   "source": [
    "install_pay = pd.read_csv(DATA_PATH + \"installments_payments.csv\")\n",
    "print(\"Shape of install_pay:\",  install_pay.shape)\n",
    "\n",
    "print(\"\\nColumns of install_pay:\")\n",
    "print(\" --- \".join(install_pay.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in (\"DAYS_ENTRY_PAYMENT\", \"AMT_PAYMENT\"):\n",
    "    install_pay[col + \"_nan\"] = install_pay[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "    install_pay[col] = install_pay[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install_pay[\"AMT_MISSING\"] = install_pay[\"AMT_INSTALMENT\"] - install_pay[\"AMT_PAYMENT\"]\n",
    "temp = install_pay.groupby(\"SK_ID_PREV\")[\"AMT_MISSING\"]\n",
    "merge_df = pd.DataFrame({\n",
    "    \"INSTALL_missing_max\": temp.max(),\n",
    "    \"INSTALL_missing_min\": temp.min(),\n",
    "    \"INSTALL_missing_med\": temp.median(),\n",
    "})\n",
    "merged_cols = [\"INSTALL_missing_max\", \"INSTALL_missing_min\", \"INSTALL_missing_med\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_install_pay\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "prev_app = prev_app.merge(right=merge_df.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df[\"no_install\"] = merge_df[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in merged_cols:\n",
    "    not_null = prev_app[col].notnull()\n",
    "    median = prev_app[not_null][col].median()\n",
    "    prev_app[col] = prev_app[col].fillna(median)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"credit\"></a>\n",
    "\n",
    "# [^](#toc) <u>Credit Card Balance</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of credit_card: (3840312, 23)\n",
      "\n",
      "Columns of credit_card:\n",
      "SK_ID_PREV --- SK_ID_CURR --- MONTHS_BALANCE --- AMT_BALANCE --- AMT_CREDIT_LIMIT_ACTUAL --- AMT_DRAWINGS_ATM_CURRENT --- AMT_DRAWINGS_CURRENT --- AMT_DRAWINGS_OTHER_CURRENT --- AMT_DRAWINGS_POS_CURRENT --- AMT_INST_MIN_REGULARITY --- AMT_PAYMENT_CURRENT --- AMT_PAYMENT_TOTAL_CURRENT --- AMT_RECEIVABLE_PRINCIPAL --- AMT_RECIVABLE --- AMT_TOTAL_RECEIVABLE --- CNT_DRAWINGS_ATM_CURRENT --- CNT_DRAWINGS_CURRENT --- CNT_DRAWINGS_OTHER_CURRENT --- CNT_DRAWINGS_POS_CURRENT --- CNT_INSTALMENT_MATURE_CUM --- NAME_CONTRACT_STATUS --- SK_DPD --- SK_DPD_DEF\n"
     ]
    }
   ],
   "source": [
    "credit_card = pd.read_csv(DATA_PATH + \"credit_card_balance.csv\")\n",
    "print(\"Shape of credit_card:\",  credit_card.shape)\n",
    "\n",
    "print(\"\\nColumns of credit_card:\")\n",
    "print(\" --- \".join(credit_card.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "### Remove outliers\n",
    "# Gets indices with outlier values\n",
    "temp = credit_card[credit_card.NAME_CONTRACT_STATUS.isin([\"Refused\", \"Approved\"])].index\n",
    "\n",
    "# Drops outlier values\n",
    "credit_card = credit_card.drop(temp, axis=0)\n",
    "\n",
    "# ------------------------------\n",
    "#### Fill in missing values\n",
    "cols = [\n",
    "        \"AMT_DRAWINGS_ATM_CURRENT\", \"AMT_DRAWINGS_OTHER_CURRENT\", \"AMT_DRAWINGS_POS_CURRENT\", \n",
    "        \"AMT_INST_MIN_REGULARITY\", \"AMT_PAYMENT_CURRENT\", \"CNT_DRAWINGS_ATM_CURRENT\", \n",
    "        \"CNT_DRAWINGS_OTHER_CURRENT\", \"CNT_DRAWINGS_POS_CURRENT\", \"CNT_INSTALMENT_MATURE_CUM\"\n",
    "]\n",
    "for col in cols:\n",
    "    not_null = credit_card[col].notnull()\n",
    "    mode = float(credit_card[not_null][col].mode())\n",
    "    credit_card[col] = credit_card[col].fillna(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = credit_card[[\"SK_ID_PREV\", \"NAME_CONTRACT_STATUS\"]]\n",
    "\n",
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "temp = get_dummies(temp, [\"NAME_CONTRACT_STATUS\"])\n",
    "temp = temp.drop(\"NAME_CONTRACT_STATUS\", axis=1)\n",
    "temp = temp.groupby(\"SK_ID_PREV\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_merge = pd.DataFrame({\n",
    "    \"AMT_BALANCE\": credit_card.groupby(\"SK_ID_PREV\").AMT_BALANCE.mean(),\n",
    "    \"SK_DPD\": credit_card.groupby(\"SK_ID_PREV\").SK_DPD.max(),\n",
    "    \"SK_DPD_DEF\": credit_card.groupby(\"SK_ID_PREV\").SK_DPD_DEF.max()\n",
    "})\n",
    "\n",
    "temp = temp.join(credit_merge)\n",
    "del credit_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_credit\"></a>\n",
    "\n",
    "### [^](#toc) <u>Merge into Previous Application</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "merged_cols = ['credit_' + col for col in temp.columns]\n",
    "temp.columns = merged_cols\n",
    "prev_app = prev_app.merge(right=temp.reset_index(), how='left', on='SK_ID_PREV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app[\"no_credit\"] = prev_app[merged_cols[0]].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "for col in merged_cols:\n",
    "    not_null = prev_app[col].notnull()\n",
    "    median = prev_app[not_null][col].median()\n",
    "    prev_app[col] = prev_app[col].fillna(median)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Data Prep\n",
    "\n",
    "### Split again into predictors, target, and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train.TARGET\n",
    "train_x = train.drop([\"TARGET\"], axis=1)\n",
    "\n",
    "test_id = test.SK_ID_CURR\n",
    "test_x  = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat([train_x, test_x])\n",
    "train_N = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_cat(df):\n",
    "    for col in [col for col in df if df[col].dtype==object]:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "full                 = fillna_cat(full)\n",
    "bureau               = fillna_cat(bureau)\n",
    "previous_application = fillna_cat(previous_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values - Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_num(df):\n",
    "    missing_cols = [col for col in df.columns if any(df[col].isnull())]\n",
    "    for col in missing_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "full                 = fillna_num(full)\n",
    "bureau               = fillna_num(bureau)\n",
    "previous_application = fillna_num(previous_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn categorical features to dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_application = pd.get_dummies(previous_application)\n",
    "bureau = pd.get_dummies(bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorize_df(df, cats):\n",
    "    for col in cats:\n",
    "        df[col], _ = pd.factorize(df[col])\n",
    "    return df \n",
    "\n",
    "# Get categorical features\n",
    "data_cats = [col for col in full.columns if full[col].dtype == 'object']\n",
    "\n",
    "# Factorize the dataframe\n",
    "full = factorize_df(full, data_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Previous Applications Data and Merge with Original Data\n",
    "\n",
    "[sban](https://www.kaggle.com/shivamb) provided the code ([link](https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of previous applications for a given ID\n",
    "prev_apps_count = previous_application[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "previous_application['SK_ID_PREV'] = previous_application['SK_ID_CURR'].map(prev_apps_count['SK_ID_PREV'])\n",
    "\n",
    "# Average values for all other features in previous applications\n",
    "prev_apps_avg = previous_application.groupby('SK_ID_CURR').mean()\n",
    "prev_apps_avg.columns = ['p_' + col for col in prev_apps_avg.columns]\n",
    "full = full.merge(right=prev_apps_avg.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Bureau Data and Merge with Original Data\n",
    "\n",
    "[sban](https://www.kaggle.com/shivamb) provided the code ([link](https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average Values for all bureau features \n",
    "bureau_avg = bureau.groupby('SK_ID_CURR').mean()\n",
    "bureau_avg['buro_count'] = bureau[['SK_ID_BUREAU','SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\n",
    "bureau_avg.columns = ['b_' + f_ for f_ in bureau_avg.columns]\n",
    "full = full.merge(right=bureau_avg.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I notice NaN values sneak into full after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = fillna_num(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split full back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = full[:train_N]\n",
    "test_x = full[train_N:]\n",
    "del full, train_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "\n",
    "# [^](#toc) <u>Models </u>\n",
    "\n",
    "### Model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kfold = KFold(n_splits=2)\n",
    "    \n",
    "def rmsle_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train_x, train_y, cv=kfold, scoring=\"neg_mean_squared_error\"))\n",
    "    print(rmse)\n",
    "    print()\n",
    "    print(sum(rmse) / len(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Regressor\n",
    "\n",
    "(Training takes 545 seconds)\n",
    "\n",
    "(Scoring takes 722 seconds)\n",
    "\n",
    "(open Markdown for notes on [LGBM](http://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.LGBMRegressor) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# LGBM Parameters\n",
    "\n",
    "boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 933 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lgbm_model = LGBMRegressor(\n",
    "                            learning_rate= 0.01,\n",
    "                            num_leaves= 48,\n",
    "                            num_iteration= 5000,\n",
    "                            max_depth= 7\n",
    "                          )\n",
    "lgbm_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(lgbm_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor\n",
    "\n",
    "(Training takes 11 seconds)\n",
    "\n",
    "(Scoring takes 13 seconds)\n",
    "\n",
    "(open Markdown for notes on [Linear Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Linear Parameters\n",
    "\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "copy_X=True,\n",
    "n_jobs=1\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 11 seconds\n"
     ]
    }
   ],
   "source": [
    "lin_model = LinearRegression()\n",
    "\n",
    "start = time.time()\n",
    "lin_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2640429   0.26175571]\n",
      "\n",
      "0.262899305367\n",
      "\n",
      "Scoring took 12 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(lin_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "WARNING: Takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27978732  0.28013387  0.28058117]\n",
      "\n",
      "0.280167454734\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "start = time.time()\n",
    "rf_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(rf_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "(Training takes 79 seconds)\n",
    "\n",
    "(Scoring takes 103 seconds)\n",
    "\n",
    "(open Markdown for notes on [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Logistic Parameters\n",
    "\n",
    "penalty=’l2’,\n",
    "dual=False,\n",
    "tol=0.0001,\n",
    "C=1.0,\n",
    "fit_intercept=True,\n",
    "intercept_scaling=1,\n",
    "class_weight=None,\n",
    "random_state=None,\n",
    "solver=’liblinear’,\n",
    "max_iter=100,\n",
    "multi_class=’ovr’,\n",
    "verbose=0,\n",
    "warm_start=False,\n",
    "n_jobs=1\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 76 seconds\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "\n",
    "start = time.time()\n",
    "log_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28573124  0.2826771 ]\n",
      "\n",
      "0.284204172243\n",
      "\n",
      "Scoring took 115 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(log_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "(Training takes 71 seconds)\n",
    "\n",
    "(Scoring takes 72 seconds)\n",
    "\n",
    "(open Markdown for notes on [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Lasso Parameters\n",
    "\n",
    "alpha=1.0,\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "precompute=False,\n",
    "copy_X=True,\n",
    "max_iter=1000,\n",
    "tol=0.0001,\n",
    "warm_start=False,\n",
    "positive=False,\n",
    "random_state=None,\n",
    "selection=’cyclic’\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 93 seconds\n"
     ]
    }
   ],
   "source": [
    "las_model = Lasso(random_state=17)\n",
    "\n",
    "start = time.time()\n",
    "las_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27082038  0.26825154]\n",
      "\n",
      "0.269535959388\n",
      "\n",
      "Scoring took 76 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(las_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "(Training takes 5 seconds)\n",
    "\n",
    "(Scoring takes 5 seconds)\n",
    "\n",
    "\n",
    "(open Markdown for notes on [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Ridge Parameters\n",
    "\n",
    "alpha=1.0,\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "copy_X=True,\n",
    "max_iter=None,\n",
    "tol=0.001,\n",
    "solver=’auto’,\n",
    "random_state=None\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 6 seconds\n"
     ]
    }
   ],
   "source": [
    "rid_model = Ridge(random_state=17)\n",
    "\n",
    "start = time.time()\n",
    "rid_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26399949  0.2616963 ]\n",
      "\n",
      "0.262847894361\n",
      "\n",
      "Scoring took 6 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(rid_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Regressor\n",
    "\n",
    "(Training takes 544, 533 seconds)\n",
    "\n",
    "(Scoring takes 453, 487 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 553 seconds\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor()\n",
    "\n",
    "start = time.time()\n",
    "xgb_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26217886  0.2599844 ]\n",
      "\n",
      "0.261081632436\n",
      "\n",
      "Scoring took 487 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(xgb_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgbm_pred = lgbm_model.predict(test_x)\n",
    "lin_pred  = lin_model.predict(test_x)\n",
    "# rf_pred   = rf_model.predict(test_x)\n",
    "log_pred  = log_model.predict(test_x)\n",
    "las_pred  = las_model.predict(test_x)\n",
    "rid_pred  = rid_model.predict(test_x)\n",
    "xgb_pred  = xgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred = 0.2 * lin_pred + 0.1*log_pred + 0.15*las_pred + 0.25*rid_pred + 0.3*xgb_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict predictions to appropriate range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = np.clip(final_pred, 0, 1)\n",
    "\n",
    "# Sanity check\n",
    "any(final_pred < 0) or any(final_pred > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "\n",
    "# [^](#toc) <u>Save file to CSV</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_id,\n",
    "    \"TARGET\": final_pred\n",
    "}).to_csv(\"../../submissions/stacked_merge_bur_bal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
