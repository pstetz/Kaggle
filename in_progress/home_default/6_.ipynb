{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small improvement over before!\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "# Table of Contents\n",
    "1.) [Imports](#imports)  \n",
    "2.) [Load data](#load)  \n",
    "3.) [Merge Bureau and Bureau_balance](#merge_bureau)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "\n",
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (307511, 123)\n",
      "Shape of test: (48744, 122)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../data/home_default/\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "test  = pd.read_csv(DATA_PATH + \"test.csv\")\n",
    "\n",
    "test['is_train'] = 0\n",
    "train['is_train'] = 1\n",
    "\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\",  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(DATA_PATH + \"bureau.csv\")\n",
    "bureau_balance = pd.read_csv(DATA_PATH + \"bureau_balance.csv\")\n",
    "previous_application = pd.read_csv(DATA_PATH + \"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merge_bureau\"></a>\n",
    "\n",
    "# Merge bureau and bureau_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup bureau balance - get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create dummy variables of categorical features\n",
    "def get_dummies(df, cats):\n",
    "    for col in cats:\n",
    "        df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "    return df \n",
    "\n",
    "bureau_balance = get_dummies(bureau_balance, [\"STATUS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge bureau and bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS_0</th>\n",
       "      <th>STATUS_1</th>\n",
       "      <th>STATUS_2</th>\n",
       "      <th>STATUS_3</th>\n",
       "      <th>STATUS_4</th>\n",
       "      <th>STATUS_5</th>\n",
       "      <th>STATUS_C</th>\n",
       "      <th>STATUS_X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5001709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001710</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001711</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001712</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              STATUS_0  STATUS_1  STATUS_2  STATUS_3  STATUS_4  STATUS_5  \\\n",
       "SK_ID_BUREAU                                                               \n",
       "5001709              0         0         0         0         0         0   \n",
       "5001710              5         0         0         0         0         0   \n",
       "5001711              3         0         0         0         0         0   \n",
       "5001712             10         0         0         0         0         0   \n",
       "5001713              0         0         0         0         0         0   \n",
       "\n",
       "              STATUS_C  STATUS_X  \n",
       "SK_ID_BUREAU                      \n",
       "5001709             86        11  \n",
       "5001710             48        30  \n",
       "5001711              0         1  \n",
       "5001712              9         0  \n",
       "5001713              0        22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance = bureau_balance.drop([\"MONTHS_BALANCE\", \"STATUS\"], axis=1)\n",
    "\n",
    "# prep for merge\n",
    "bureau_balance = bureau_balance.groupby(\"SK_ID_BUREAU\").sum()\n",
    "\n",
    "# Merge\n",
    "bureau = bureau.merge(right=bureau_balance.reset_index(), how='left', on='SK_ID_BUREAU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in new missing values with -1\n",
    "\n",
    "There won't be any effect if we replace NaN with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                      0\n",
       "SK_ID_BUREAU                    0\n",
       "CREDIT_ACTIVE                   0\n",
       "CREDIT_CURRENCY                 0\n",
       "DAYS_CREDIT                     0\n",
       "CREDIT_DAY_OVERDUE              0\n",
       "DAYS_CREDIT_ENDDATE        105553\n",
       "DAYS_ENDDATE_FACT          633653\n",
       "AMT_CREDIT_MAX_OVERDUE    1124488\n",
       "CNT_CREDIT_PROLONG              0\n",
       "AMT_CREDIT_SUM                 13\n",
       "AMT_CREDIT_SUM_DEBT        257669\n",
       "AMT_CREDIT_SUM_LIMIT       591780\n",
       "AMT_CREDIT_SUM_OVERDUE          0\n",
       "CREDIT_TYPE                     0\n",
       "DAYS_CREDIT_UPDATE              0\n",
       "AMT_ANNUITY               1226791\n",
       "STATUS_0                        0\n",
       "STATUS_1                        0\n",
       "STATUS_2                        0\n",
       "STATUS_3                        0\n",
       "STATUS_4                        0\n",
       "STATUS_5                        0\n",
       "STATUS_C                        0\n",
       "STATUS_X                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau[[\"STATUS_0\", \"STATUS_1\", \"STATUS_2\", \"STATUS_3\", \"STATUS_4\", \"STATUS_5\", \"STATUS_C\", \"STATUS_X\"]] = (\n",
    "    bureau[[\"STATUS_0\", \"STATUS_1\", \"STATUS_2\", \"STATUS_3\", \"STATUS_4\", \"STATUS_5\", \"STATUS_C\", \"STATUS_X\"]]\n",
    "        .fillna(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split again into predictors, target, and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train.TARGET\n",
    "train_x = train.drop([\"TARGET\"], axis=1)\n",
    "\n",
    "test_id = test.SK_ID_CURR\n",
    "test_x  = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = pd.concat([train_x, test_x])\n",
    "train_N = len(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values - Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_cat(df):\n",
    "    for col in [col for col in df if df[col].dtype==object]:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "full                 = fillna_cat(full)\n",
    "bureau               = fillna_cat(bureau)\n",
    "previous_application = fillna_cat(previous_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values - Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_num(df):\n",
    "    missing_cols = [col for col in df.columns if any(df[col].isnull())]\n",
    "    for col in missing_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "full                 = fillna_num(full)\n",
    "bureau               = fillna_num(bureau)\n",
    "previous_application = fillna_num(previous_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn categorical features to dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_application = pd.get_dummies(previous_application)\n",
    "bureau = pd.get_dummies(bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorize_df(df, cats):\n",
    "    for col in cats:\n",
    "        df[col], _ = pd.factorize(df[col])\n",
    "    return df \n",
    "\n",
    "# Get categorical features\n",
    "data_cats = [col for col in full.columns if full[col].dtype == 'object']\n",
    "\n",
    "# Factorize the dataframe\n",
    "full = factorize_df(full, data_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Previous Applications Data and Merge with Original Data\n",
    "\n",
    "[sban](https://www.kaggle.com/shivamb) provided the code ([link](https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count the number of previous applications for a given ID\n",
    "prev_apps_count = previous_application[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "previous_application['SK_ID_PREV'] = previous_application['SK_ID_CURR'].map(prev_apps_count['SK_ID_PREV'])\n",
    "\n",
    "# Average values for all other features in previous applications\n",
    "prev_apps_avg = previous_application.groupby('SK_ID_CURR').mean()\n",
    "prev_apps_avg.columns = ['p_' + col for col in prev_apps_avg.columns]\n",
    "full = full.merge(right=prev_apps_avg.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Bureau Data and Merge with Original Data\n",
    "\n",
    "[sban](https://www.kaggle.com/shivamb) provided the code ([link](https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average Values for all bureau features \n",
    "bureau_avg = bureau.groupby('SK_ID_CURR').mean()\n",
    "bureau_avg['buro_count'] = bureau[['SK_ID_BUREAU','SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\n",
    "bureau_avg.columns = ['b_' + f_ for f_ in bureau_avg.columns]\n",
    "full = full.merge(right=bureau_avg.reset_index(), how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I notice NaN values sneak into full after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = fillna_num(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split full back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = full[:train_N]\n",
    "test_x = full[train_N:]\n",
    "del full, train_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kfold = KFold(n_splits=2)\n",
    "    \n",
    "def rmsle_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train_x, train_y, cv=kfold, scoring=\"neg_mean_squared_error\"))\n",
    "    print(rmse)\n",
    "    print()\n",
    "    print(sum(rmse) / len(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Regressor\n",
    "\n",
    "(Training takes 545 seconds)\n",
    "\n",
    "(Scoring takes 722 seconds)\n",
    "\n",
    "(open Markdown for notes on [LGBM](http://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.LGBMRegressor) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# LGBM Parameters\n",
    "\n",
    "boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 933 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lgbm_model = LGBMRegressor(\n",
    "                            learning_rate= 0.01,\n",
    "                            num_leaves= 48,\n",
    "                            num_iteration= 5000,\n",
    "                            max_depth= 7\n",
    "                          )\n",
    "lgbm_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(lgbm_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressor\n",
    "\n",
    "(Training takes 11 seconds)\n",
    "\n",
    "(Scoring takes 13 seconds)\n",
    "\n",
    "(open Markdown for notes on [Linear Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Linear Parameters\n",
    "\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "copy_X=True,\n",
    "n_jobs=1\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 11 seconds\n"
     ]
    }
   ],
   "source": [
    "lin_model = LinearRegression()\n",
    "\n",
    "start = time.time()\n",
    "lin_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2640429   0.26175571]\n",
      "\n",
      "0.262899305367\n",
      "\n",
      "Scoring took 12 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(lin_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "WARNING: Takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27978732  0.28013387  0.28058117]\n",
      "\n",
      "0.280167454734\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "start = time.time()\n",
    "rf_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(rf_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "(Training takes 79 seconds)\n",
    "\n",
    "(Scoring takes 103 seconds)\n",
    "\n",
    "(open Markdown for notes on [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Logistic Parameters\n",
    "\n",
    "penalty=’l2’,\n",
    "dual=False,\n",
    "tol=0.0001,\n",
    "C=1.0,\n",
    "fit_intercept=True,\n",
    "intercept_scaling=1,\n",
    "class_weight=None,\n",
    "random_state=None,\n",
    "solver=’liblinear’,\n",
    "max_iter=100,\n",
    "multi_class=’ovr’,\n",
    "verbose=0,\n",
    "warm_start=False,\n",
    "n_jobs=1\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 76 seconds\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "\n",
    "start = time.time()\n",
    "log_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28573124  0.2826771 ]\n",
      "\n",
      "0.284204172243\n",
      "\n",
      "Scoring took 115 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(log_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "(Training takes 71 seconds)\n",
    "\n",
    "(Scoring takes 72 seconds)\n",
    "\n",
    "(open Markdown for notes on [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Lasso Parameters\n",
    "\n",
    "alpha=1.0,\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "precompute=False,\n",
    "copy_X=True,\n",
    "max_iter=1000,\n",
    "tol=0.0001,\n",
    "warm_start=False,\n",
    "positive=False,\n",
    "random_state=None,\n",
    "selection=’cyclic’\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 93 seconds\n"
     ]
    }
   ],
   "source": [
    "las_model = Lasso(random_state=17)\n",
    "\n",
    "start = time.time()\n",
    "las_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27082038  0.26825154]\n",
      "\n",
      "0.269535959388\n",
      "\n",
      "Scoring took 76 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(las_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "(Training takes 5 seconds)\n",
    "\n",
    "(Scoring takes 5 seconds)\n",
    "\n",
    "\n",
    "(open Markdown for notes on [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and parameter search attempts)\n",
    "\n",
    "<div hidden>\n",
    "\n",
    "# Ridge Parameters\n",
    "\n",
    "alpha=1.0,\n",
    "fit_intercept=True,\n",
    "normalize=False,\n",
    "copy_X=True,\n",
    "max_iter=None,\n",
    "tol=0.001,\n",
    "solver=’auto’,\n",
    "random_state=None\n",
    "\n",
    "<\\div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 6 seconds\n"
     ]
    }
   ],
   "source": [
    "rid_model = Ridge(random_state=17)\n",
    "\n",
    "start = time.time()\n",
    "rid_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26399949  0.2616963 ]\n",
      "\n",
      "0.262847894361\n",
      "\n",
      "Scoring took 6 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(rid_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Regressor\n",
    "\n",
    "(Training takes 544, 533 seconds)\n",
    "\n",
    "(Scoring takes 453, 487 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 553 seconds\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBRegressor()\n",
    "\n",
    "start = time.time()\n",
    "xgb_model.fit(train_x, train_y)\n",
    "print(\"Training took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26217886  0.2599844 ]\n",
      "\n",
      "0.261081632436\n",
      "\n",
      "Scoring took 487 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rmsle_cv(xgb_model)\n",
    "print(\"\\nScoring took {} seconds\".format(round(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lgbm_pred = lgbm_model.predict(test_x)\n",
    "lin_pred  = lin_model.predict(test_x)\n",
    "# rf_pred   = rf_model.predict(test_x)\n",
    "log_pred  = log_model.predict(test_x)\n",
    "las_pred  = las_model.predict(test_x)\n",
    "rid_pred  = rid_model.predict(test_x)\n",
    "xgb_pred  = xgb_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred = 0.2 * lin_pred + 0.1*log_pred + 0.15*las_pred + 0.25*rid_pred + 0.3*xgb_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict predictions to appropriate range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = np.clip(final_pred, 0, 1)\n",
    "\n",
    "# Sanity check\n",
    "any(final_pred < 0) or any(final_pred > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_id,\n",
    "    \"TARGET\": final_pred\n",
    "}).to_csv(\"../../submissions/stacked_merge_bur_bal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
