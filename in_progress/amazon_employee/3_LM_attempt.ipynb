{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Original code by Miroslaw Horbal\n",
    "Modified by Luca Massaroon\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import metrics, cross_validation, linear_model\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_data(data, degree=3, cutoff = 1, hash=hash):\n",
    "    \"\"\" \n",
    "    numpy.array -> numpy.array\n",
    "    \n",
    "    Groups all columns of data into all combinations of triples\n",
    "    \"\"\"\n",
    "    \n",
    "    new_data = []\n",
    "    m,n = data.shape\n",
    "    for indexes in combinations(range(n), degree):\n",
    "        new_data.append([hash(tuple(v)) for v in data[:,indexes]])\n",
    "    for z in range(len(new_data)):\n",
    "        counts = dict()\n",
    "        useful = dict()\n",
    "        for item in new_data[z]:\n",
    "            if item in counts:\n",
    "                counts[item] += 1\n",
    "                if counts[item] > cutoff:\n",
    "                    useful[item] = 1\n",
    "            else:\n",
    "                counts[item] = 1\n",
    "        for j in range(len(new_data[z])):\n",
    "            if not new_data[z][j] in useful:\n",
    "                new_data[z][j] = 0\n",
    "    return np.array(new_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneHotEncoder(data, keymap=None):\n",
    "     \"\"\"\n",
    "     OneHotEncoder takes data matrix with categorical columns and\n",
    "     converts it to a sparse binary matrix.\n",
    "     \n",
    "     Returns sparse binary matrix and keymap mapping categories to indexes.\n",
    "     If a keymap is supplied on input it will be used instead of creating one\n",
    "     and any categories appearing in the data that are not in the keymap are\n",
    "     ignored\n",
    "     \"\"\"\n",
    "     if keymap is None:\n",
    "          keymap = []\n",
    "          for col in data.T:\n",
    "               uniques = set(list(col))\n",
    "               keymap.append(dict((key, i) for i, key in enumerate(uniques)))\n",
    "     total_pts = data.shape[0]\n",
    "     outdat = []\n",
    "     for i, col in enumerate(data.T):\n",
    "          km = keymap[i]\n",
    "          num_labels = len(km)\n",
    "          spmat = sparse.lil_matrix((total_pts, num_labels))\n",
    "          for j, val in enumerate(col):\n",
    "               if val in km:\n",
    "                    spmat[j, km[val]] = 1\n",
    "          outdat.append(spmat)\n",
    "     outdat = sparse.hstack(outdat).tocsr()\n",
    "     return outdat, keymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test_submission(filename, prediction):\n",
    "    content = ['id,ACTION']\n",
    "    for i, p in enumerate(prediction):\n",
    "        content.append('%i,%f' %(i+1,p))\n",
    "    f = open(filename, 'w')\n",
    "    f.write('\\n'.join(content))\n",
    "    f.close()\n",
    "    print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred):\n",
    "    return metrics.auc_score(y_true, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_worker(args):\n",
    "    X, y, model, j, SEED = args\n",
    "    X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "                                       X, y, test_size=.15, \n",
    "                                       random_state = j*SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_cv)[:,1]\n",
    "    auc = metrics.auc_score(y_cv, preds)\n",
    "    return auc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_loop(X, y, model, N, pool, SEED): \n",
    "    instructions = [(X, y, model, i, SEED) for i in range(N)]\n",
    "    pooled_auc = pool.map(validation_worker, instructions)        \n",
    "    return np.median(np.array(pooled_auc))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_path, test_path, submit_path, initial_solution=list(), finalize=False):    \n",
    "    global SEED\n",
    "    global N_JOBS\n",
    "    \n",
    "    SEED = random.randint(0,2500)\n",
    "    print(\"Random seed is:\",SEED)\n",
    "    N_JOBS = max(1,min(10, multiprocessing.cpu_count()-1))\n",
    "    N = 10 # Cross validation parameter\n",
    "    small_change = 0.00005 # set the smallest acceptable change in the model performance\n",
    "    \n",
    "    print(\"Reading dataset...\")\n",
    "    train_data = pd.read_csv(train)\n",
    "    test_data = pd.read_csv(test)\n",
    "    all_data = np.vstack((train_data.ix[:,1:-1], test_data.ix[:,1:-1]))\n",
    "\n",
    "    num_train = np.shape(train_data)[0]\n",
    "    \n",
    "    # Transform data\n",
    "    print(\"Transforming data...\")\n",
    "    dp1 = group_data(all_data, degree=2, cutoff=2) \n",
    "    dt1 = group_data(all_data, degree=3, cutoff=2)\n",
    "    dz1 = group_data(all_data, degree=4, cutoff=2)\n",
    "    dp2 = group_data(all_data, degree=5, cutoff=2)\n",
    "    dp3 = group_data(all_data, degree=6, cutoff=2) \n",
    "\n",
    "    y = np.array(train_data.ACTION)\n",
    "    X = all_data[:num_train]\n",
    "    X_2  = dp1[:num_train]\n",
    "    X_3  = dt1[:num_train]\n",
    "    X_4  = dz1[:num_train]\n",
    "    X_5  = dp2[:num_train]\n",
    "    X_6  = dp3[:num_train]\n",
    "\n",
    "    X_test = all_data[num_train:]\n",
    "    X_test_2 = dp1[num_train:]\n",
    "    X_test_3 = dt1[num_train:]\n",
    "    X_test_4 = dz1[num_train:]\n",
    "    X_test_5 = dp2[num_train:]\n",
    "    X_test_6 = dp3[num_train:]\n",
    "\n",
    "    X_train_all = np.hstack((X, X_2, X_3, X_4, X_5, X_6))\n",
    "    X_test_all = np.hstack((X_test, X_test_2, X_test_3, X_test_4, X_test_5, X_test_6))\n",
    "    num_features = X_train_all.shape[1]\n",
    "    \n",
    "    model = linear_model.LogisticRegression()\n",
    "    \n",
    "    # Xts holds one hot encodings for each individual feature in memory\n",
    "    # speeding up feature selection \n",
    "    Xts = [OneHotEncoder(X_train_all[:,[i]])[0] for i in range(num_features)]\n",
    "    \n",
    "    print(\"Performing greedy feature selection...\")\n",
    "    \n",
    "    p = multiprocessing.Pool(N_JOBS)\n",
    "    good_features = set(initial_solution)\n",
    "    \n",
    "    if len(good_features) == 0:\n",
    "        score_hist = []\n",
    "    else:\n",
    "        feats = list(good_features)\n",
    "        Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "        score_hist = [(cv_loop(Xt, y, model, N, p, SEED),-1)] \n",
    "    \n",
    "    if finalize:\n",
    "        good_features = initial_solution\n",
    "        print(\"Final features: {}\".format(sorted(list(good_features))))\n",
    "    else:\n",
    "        # Greedy feature selection loop\n",
    "        maxscore = 0\n",
    "        while len(score_hist) < 2 or (score_hist[-1][0] - score_hist[-2][0]) > small_change:\n",
    "            scores = []\n",
    "            for f in range(len(Xts)):\n",
    "                if f not in good_features:\n",
    "                    feats = list(good_features) + [f]\n",
    "                    Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "                    score = cv_loop(Xt, y, model, N, p, SEED)\n",
    "                    scores.append((score, f))\n",
    "                    if score > maxscore:\n",
    "                        print(\"Feature: {} Mean AUC: {}\".format((f, score)))\n",
    "                        maxscore = score\n",
    "            good_features.add(sorted(scores)[-1][1])\n",
    "            score_hist.append(sorted(scores)[-1])\n",
    "            if len(good_features) > 2 :\n",
    "                print(\"Pruning...\")\n",
    "                to_be_removed = None \n",
    "                gain = 0\n",
    "                baseline = score_hist[-1][0]\n",
    "                for f,target in enumerate(good_features):\n",
    "                    feats = list(good_features)\n",
    "                    feats.remove(target)\n",
    "                    Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "                    score = cv_loop(Xt, y, model, N, p, SEED)\n",
    "                    if score > baseline and (score-baseline) > gain:\n",
    "                        gain = score-baseline\n",
    "                        to_be_removed = target\n",
    "                        print(\"Removing {} will improve AUC by {}\".format(target, gain))\n",
    "                if to_be_removed:\n",
    "                    good_features.discard(to_be_removed)\n",
    "                    score_hist.append((baseline+gain,target*-1))\n",
    "                    print(\"Current features: {}\".format(sorted(list(good_features))))\n",
    "        \n",
    "        # Remove last added feature from good_features\n",
    "        # good_features.remove(score_hist[-1][1])\n",
    "        good_features = sorted(list(good_features))\n",
    "        print(\"Selected features %s\" % good_features)\n",
    "        print(\"History:\",score_hist)\n",
    "      \n",
    "    print(\"Performing hyperparameter selection...\")\n",
    "    # Hyperparameter selection loop\n",
    "    score_hist = []\n",
    "    Xt = sparse.hstack([Xts[j] for j in good_features]).tocsr()\n",
    "    Cvals = np.logspace(-4, 4, 15, base=2)\n",
    "    for C in Cvals:\n",
    "        model.C = C\n",
    "        score = cv_loop(Xt, y, model, N, p, SEED)\n",
    "        score_hist.append((score,C))\n",
    "        print(\"C: {} Mean AUC: {}\".format(C, score))\n",
    "    bestC = sorted(score_hist)[-1][1]\n",
    "    bestscore = sorted(score_hist)[-1][0]\n",
    "    print(\"Best C value: {}\".format((bestC)))\n",
    "    \n",
    "    model.C = bestC # Specifies the best strength of the regularization. \n",
    "    \n",
    "    Xt = np.vstack((X_train_all[:,good_features], X_test_all[:,good_features]))\n",
    "    Xt, keymap = OneHotEncoder(Xt)\n",
    "    X_train = Xt[:num_train]\n",
    "    X_test = Xt[num_train:]\n",
    "    \n",
    "    print(\"Training full model...\")\n",
    "    model.fit(X_train, y)\n",
    "    \n",
    "    print(\"Making prediction and saving results...\")\n",
    "    preds = model.predict_proba(X_test)[:,1]\n",
    "    create_test_submission(submit+str(bestscore)+'.csv', preds)\n",
    "    p.terminate() \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    args = { 'train':  '../../data/amazon_employee/train.csv',\n",
    "             'test':   '../../data/amazon_employee/test.csv',\n",
    "             'submit': 'logistic_regression_pred_submission_', \n",
    "             'initial_solution': [],\n",
    "             'finalize': False\n",
    "             }\n",
    "    main(**args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
