{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score:\n",
    "\n",
    "Trying [Jo√£o Pedro Peinado](https://www.kaggle.com/joaopmpeinado) approach ([his work](https://www.kaggle.com/joaopmpeinado/talkingdata-xgboost-lb-0-966/output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeFeatures(df):\n",
    "    # Make some new features with click_time column\n",
    "    df['datetime'] = pd.to_datetime(df['click_time'])\n",
    "    df['dow']      = df['datetime'].dt.dayofweek\n",
    "    df[\"doy\"]      = df[\"datetime\"].dt.dayofyear\n",
    "    #df[\"dteom\"]    = df[\"datetime\"].dt.daysinmonth - df[\"datetime\"].dt.day\n",
    "    df.drop(['click_time', 'datetime'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Change this for validation with 10% from train\n",
    "is_valid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68.96785998344421] Finished to load data\n"
     ]
    }
   ],
   "source": [
    "path = '../../data/talking_data/'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns  = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "# Read the last lines because they are more impacting in training than the starting lines\n",
    "train = pd.read_csv(path+\"train_r.csv\", nrows=61000000, usecols=train_columns, dtype=dtypes)\n",
    "test = pd.read_csv(path+\"test.csv\", usecols=test_columns, dtype=dtypes)\n",
    "\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.689590215682983] Time to finish\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Drop the IP and the columns from target\n",
    "y = train['is_attributed']\n",
    "train.drop(['is_attributed'], axis=1, inplace=True)\n",
    "\n",
    "# Drop IP and ID from test rows\n",
    "sub = pd.DataFrame()\n",
    "#sub['click_id'] = test['click_id'].astype('int')\n",
    "test.drop(['click_id'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "nrow_train = train.shape[0]\n",
    "merge = pd.concat([train, test])\n",
    "\n",
    "del train, test\n",
    "gc.collect()\n",
    "\n",
    "print('[{}] Time to finish'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52.44953012466431] Time to finish\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Count the number of clicks by ip\n",
    "ip_count = merge.groupby(['ip'])['channel'].count().reset_index()\n",
    "ip_count.columns = ['ip', 'clicks_by_ip']\n",
    "merge = pd.merge(merge, ip_count, on='ip', how='left', sort=False)\n",
    "merge['clicks_by_ip'] = merge['clicks_by_ip'].astype('uint16')\n",
    "merge.drop('ip', axis=1, inplace=True)\n",
    "\n",
    "train = merge[:nrow_train]\n",
    "test = merge[nrow_train:]\n",
    "\n",
    "del test, merge\n",
    "gc.collect()\n",
    "\n",
    "print('[{}] Time to finish'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.475963830947876] Time to finish\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train = timeFeatures(train)\n",
    "gc.collect()\n",
    "\n",
    "print('[{}] Time to finish'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.959572\n",
      "[1]\ttrain-auc:0.962121\n",
      "[2]\ttrain-auc:0.962985\n",
      "[3]\ttrain-auc:0.962546\n",
      "[4]\ttrain-auc:0.964779\n",
      "[471.81199073791504] Finish XGBoost Training\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Set the params(this params from Pranav kernel) for xgboost model\n",
    "params = {'eta': 0.3,\n",
    "          'tree_method': \"hist\",\n",
    "          'grow_policy': \"lossguide\",\n",
    "          'max_leaves': 1400,  \n",
    "          'max_depth': 0, \n",
    "          'subsample': 0.9, \n",
    "          'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':0,\n",
    "          'alpha':4,\n",
    "          'objective': 'binary:logistic', \n",
    "          'scale_pos_weight':9,\n",
    "          'eval_metric': 'auc', \n",
    "          'nthread':8,\n",
    "          'random_state': 99, \n",
    "          'silent': True}\n",
    "          \n",
    "\n",
    "if (is_valid == True):\n",
    "    # Get 10% of train dataset to use as validation\n",
    "    x1, x2, y1, y2 = train_test_split(train, y, test_size=0.1, random_state=99)\n",
    "    dtrain = xgb.DMatrix(x1, y1)\n",
    "    dvalid = xgb.DMatrix(x2, y2)\n",
    "    del x1, y1, x2, y2 \n",
    "    gc.collect()\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "    model = xgb.train(params, dtrain, 200, watchlist, maximize=True, early_stopping_rounds = 25, verbose_eval=5)\n",
    "    del dvalid\n",
    "else:\n",
    "    dtrain = xgb.DMatrix(train, y)\n",
    "    del train, y\n",
    "    gc.collect()\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, 5, watchlist, maximize=True, verbose_eval=1)\n",
    "\n",
    "del dtrain\n",
    "gc.collect()\n",
    "\n",
    "print('[{}] Finish XGBoost Training'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1101ab198>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the feature importance from xgboost\n",
    "_ = plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the test for predict \n",
    "test = pd.read_csv(path+\"test.csv\", usecols=test_columns, dtype=dtypes)\n",
    "test = pd.merge(test, ip_count, on='ip', how='left', sort=False)\n",
    "del ip_count\n",
    "gc.collect()\n",
    "\n",
    "sub['click_id'] = test['click_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['clicks_by_ip'] = test['clicks_by_ip'].astype('uint16')\n",
    "test = timeFeatures(test)\n",
    "test.drop(['click_id', 'ip'], axis=1, inplace=True)\n",
    "dtest = xgb.DMatrix(test)\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the predictions\n",
    "sub['is_attributed'] = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "sub.to_csv('../../submissions/joan_xgb.csv', float_format='%.8f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
